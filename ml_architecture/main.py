import os
import sys
import logging
import traceback
import gc
from typing import Optional
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Body, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# Add the project root directory to the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Import memory management
try:
    from ml_architecture.config.memory_config import MemoryManager, check_memory_usage
    # Apply memory optimizations for deployment
    MemoryManager.optimize_for_deployment()
except ImportError:
    # Fallback if memory config is not available
    class MemoryManager:
        @staticmethod
        def log_memory_usage(stage: str):
            pass
        @staticmethod
        def force_garbage_collection():
            gc.collect()
    
    def check_memory_usage():
        return True

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="CV Analysis API",
    description="API for analyzing CVs and matching with job descriptions",
    version="1.0.0"
)

# Lazy loading - ch·ªâ kh·ªüi t·∫°o analyzer khi c·∫ßn
analyzer = None

from fastapi import Request
@app.middleware("http")
async def log_exceptions(request: Request, call_next):
    try:
        return await call_next(request)
    except Exception as exc:
        import traceback
        print("=== EXCEPTION CAUGHT BY MIDDLEWARE ===")
        traceback.print_exc()
        raise

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def get_analyzer():
    """Lazy loading cho analyzer ƒë·ªÉ ti·∫øt ki·ªám memory"""
    global analyzer
    if analyzer is None:
        try:
            # Log memory before loading analyzer
            MemoryManager.log_memory_usage("before_analyzer_init")
            
            # Force garbage collection before loading
            MemoryManager.force_garbage_collection()
            
            from ml_architecture.services.cv_evaluation_service import CVEvaluationService
            analyzer = CVEvaluationService()
            
            # Log memory after loading analyzer
            MemoryManager.log_memory_usage("after_analyzer_init")
            
            logger.info("‚úÖ CV Analyzer ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o CV Analyzer: {e}")
            # Force garbage collection on error
            MemoryManager.force_garbage_collection()
            raise HTTPException(
                status_code=500,
                detail="L·ªói server: Kh√¥ng th·ªÉ kh·ªüi t·∫°o CV Analyzer"
            )
    
    # Double check analyzer is not None
    if analyzer is None:
        logger.error("‚ùå Analyzer is still None after initialization attempt")
        raise HTTPException(
            status_code=500,
            detail="L·ªói server: Analyzer kh√¥ng ƒë∆∞·ª£c kh·ªüi t·∫°o"
        )
    
    return analyzer

async def process_cv_file(cv_file: UploadFile) -> str:
    """Process CV file and extract text content"""
    try:
        # Read file content
        content = await cv_file.read()
        
        # Check file type and process accordingly
        file_extension = cv_file.filename.lower().split('.')[-1] if cv_file.filename else ''
        
        if file_extension == 'pdf':
            # For PDF files, try to extract text with better error handling
            try:
                import PyPDF2
                import io
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(content))
                cv_text = ""
                for page in pdf_reader.pages:
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            cv_text += page_text + "\n"
                    except Exception as page_error:
                        logger.warning(f"Error extracting text from page: {page_error}")
                        continue
                return cv_text.strip() if cv_text.strip() else "PDF content could not be extracted"
            except Exception as pdf_error:
                logger.warning(f"PDF parsing failed: {pdf_error}, trying alternative method")
                try:
                    # Try alternative PDF parsing
                    import fitz  # PyMuPDF
                    doc = fitz.open(stream=content, filetype="pdf")
                    cv_text = ""
                    for page in doc:
                        cv_text += page.get_text() + "\n"
                    doc.close()
                    return cv_text.strip() if cv_text.strip() else "PDF content could not be extracted"
                except ImportError:
                    logger.warning("PyMuPDF not available")
                except Exception as fitz_error:
                    logger.warning(f"PyMuPDF parsing failed: {fitz_error}")
                
                # Fallback: return a placeholder text
                return "PDF content could not be extracted. Please try uploading a text file instead."
        elif file_extension in ['txt', 'docx']:
            # For text files, decode as UTF-8 with error handling
            return content.decode('utf-8', errors='ignore')
        else:
            # Default: try to decode as text
            return content.decode('utf-8', errors='ignore')
            
    except Exception as e:
        logger.error(f"Error processing CV file: {e}")
        raise HTTPException(status_code=400, detail=f"Error processing CV file: {str(e)}")

@app.post("/analyze-cv")
async def analyze_cv(
    cv_file: UploadFile = File(...),
    job_category: str = Form(...),
    job_position: str = Form(...),
    jd_text: str = Form(...),
    job_requirements: str = Form(None)
):
    """
    Ph√¢n t√≠ch CV t·ª´ file v√† ƒë√°nh gi√° m·ª©c ƒë·ªô ph√π h·ª£p v·ªõi JD/JR
    """
    try:
        # Check memory usage before processing
        if not check_memory_usage():
            raise HTTPException(
                status_code=503,
                detail="Server is under high memory load. Please try again later."
            )
        
        # Lazy load analyzer
        analyzer = get_analyzer()
        
        # X·ª≠ l√Ω file CV ƒë·ªÉ l·∫•y n·ªôi dung text
        try:
            logger.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {cv_file.filename}")
            cv_content = await process_cv_file(cv_file)
            logger.info("X·ª≠ l√Ω file CV th√†nh c√¥ng, thu ƒë∆∞·ª£c n·ªôi dung text.")
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω file CV: {str(e)}\n{traceback.format_exc()}")
            raise HTTPException(
                status_code=400,
                detail=f"L·ªói kh√¥ng th·ªÉ x·ª≠ l√Ω file CV: {str(e)}"
            )

        if not cv_content:
            raise HTTPException(
                status_code=400,
                detail="N·ªôi dung CV kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            )

        # LLM extraction cho CV - lazy load
        try:
            from ml_architecture.services.llm_api_extractor_cv import extract_cv_info_from_text
            llm_cv_result = extract_cv_info_from_text(cv_content)
            logging.info("[LLM Extraction] CV: %s", llm_cv_result)
        except Exception as e:
            logger.warning(f"LLM extraction failed: {e}")
            llm_cv_result = {}

        # Ph√¢n t√≠ch CV v·ªõi JD b·∫±ng b·ªô ph√¢n t√≠ch chi ti·∫øt m·ªõi
        try:
            logger.info("B·∫Øt ƒë·∫ßu ph√¢n t√≠ch chi ti·∫øt CV v√† JD...")
            logger.info(f"Job Category: {job_category}")
            logger.info(f"Job Position: {job_position}")
            
            analysis_result = analyzer.evaluate_cv_comprehensive(
                cv_text=cv_content,
                job_category=job_category,
                job_position=job_position,
                jd_text=jd_text,
                job_requirements=job_requirements
            )
            logger.info("Ph√¢n t√≠ch chi ti·∫øt ho√†n t·∫•t.")
            
            # Log th√¥ng tin c√° nh√¢n v√† feedback c√° nh√¢n h√≥a
            if 'personal_info' in analysis_result:
                personal_info = analysis_result['personal_info']
                logger.info(f"üë§ ·ª®ng vi√™n: {personal_info.get('full_name', 'N/A')}")
                logger.info(f"üíº V·ªã tr√≠ ·ª©ng tuy·ªÉn: {personal_info.get('job_position', 'N/A')}")
            
            if 'personalized_feedback' in analysis_result:
                personalized = analysis_result['personalized_feedback']
                logger.info(f"üí¨ Feedback c√° nh√¢n h√≥a: {personalized.get('personalized_assessment', 'N/A')}")
                logger.info(f"üéØ Assessment Level: {personalized.get('assessment_level', 'N/A')}")
            
            # Clean up memory
            MemoryManager.force_garbage_collection()
            
        except Exception as e:
            logger.error(f"L·ªói khi ph√¢n t√≠ch CV: {str(e)}\n{traceback.format_exc()}")
            raise HTTPException(
                status_code=500,
                detail=f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}"
            )

        return analysis_result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói server: {str(e)}"
        )

@app.post("/analyze-jd")
async def analyze_jd(jd_text: str = Form(...)):
    """
    Ph√¢n t√≠ch JD v√† tr√≠ch xu·∫•t skills
    """
    try:
        # Check memory usage before processing
        if not check_memory_usage():
            raise HTTPException(
                status_code=503,
                detail="Server is under high memory load. Please try again later."
            )
        
        # Lazy load analyzer
        analyzer = get_analyzer()
        
        # Tr√≠ch xu·∫•t skills t·ª´ JD - lazy load
        try:
            from ml_architecture.services.llm_api_extractor_jd import extract_skills_from_jd
            jd_skills = extract_skills_from_jd(jd_text)
        except Exception as e:
            logger.warning(f"LLM extraction failed: {e}")
            jd_skills = []
        
        # Ph√¢n t√≠ch chi ti·∫øt JD - lazy load
        try:
            from ml_architecture.data.jd_analysis_system import JDAnalysisSystem
            jd_analyzer = JDAnalysisSystem()
            jd_analysis = jd_analyzer.analyze_single_jd(jd_text)
        except Exception as e:
            logger.warning(f"JD analysis failed: {e}")
            jd_analysis = {}
        
        # Clean up memory
        MemoryManager.force_garbage_collection()
        
        return {
            "jd_text": jd_text,
            "extracted_skills": jd_skills,
            "analysis": jd_analysis
        }
    except Exception as e:
        logger.error(f"L·ªói khi ph√¢n t√≠ch JD: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói khi ph√¢n t√≠ch JD: {str(e)}"
        )

@app.post("/extract-jd-skills-api")
async def extract_jd_skills_api(jd_text: str = Form(...)):
    """Extract skills from JD using LLM API (OpenAI)"""
    try:
        from ml_architecture.services.llm_api_extractor_jd import extract_skills_from_jd
        skills = extract_skills_from_jd(jd_text)
        return {"skills": skills}
    except Exception as e:
        logger.error(f"LLM API extraction failed: {e}")
        raise HTTPException(status_code=500, detail="LLM API extraction failed")

@app.post("/extract-personal-info")
async def extract_personal_info(cv_file: UploadFile = File(...)):
    """Tr√≠ch xu·∫•t th√¥ng tin c√° nh√¢n t·ª´ CV"""
    try:
        # Check memory usage before processing
        if not check_memory_usage():
            raise HTTPException(
                status_code=503,
                detail="Server is under high memory load. Please try again later."
            )
        
        # X·ª≠ l√Ω file CV ƒë·ªÉ l·∫•y n·ªôi dung text
        try:
            logger.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω file: {cv_file.filename}")
            cv_content = await process_cv_file(cv_file)
            logger.info("X·ª≠ l√Ω file CV th√†nh c√¥ng, thu ƒë∆∞·ª£c n·ªôi dung text.")
        except Exception as e:
            logger.error(f"L·ªói khi x·ª≠ l√Ω file CV: {str(e)}")
            raise HTTPException(
                status_code=400,
                detail=f"L·ªói kh√¥ng th·ªÉ x·ª≠ l√Ω file CV: {str(e)}"
            )

        if not cv_content:
            raise HTTPException(
                status_code=400,
                detail="N·ªôi dung CV kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng"
            )

        # Tr√≠ch xu·∫•t th√¥ng tin c√° nh√¢n
        try:
            from ml_architecture.services.llm_personal_info_extractor import LLMPersonalInfoExtractor
            extractor = LLMPersonalInfoExtractor()
            personal_info = extractor.extract_personal_info(cv_content)
            
            logger.info(f"‚úÖ Tr√≠ch xu·∫•t th√¥ng tin c√° nh√¢n th√†nh c√¥ng: {personal_info.full_name}")
            
            return {
                "personal_info": {
                    "full_name": personal_info.full_name,
                    "job_position": personal_info.job_position
                },
                "cv_content_preview": cv_content[:500] + "..." if len(cv_content) > 500 else cv_content
            }
            
        except Exception as e:
            logger.error(f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin c√° nh√¢n: {str(e)}")
            raise HTTPException(
                status_code=500,
                detail=f"L·ªói khi tr√≠ch xu·∫•t th√¥ng tin c√° nh√¢n: {str(e)}"
            )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói server: {str(e)}"
        )

@app.get("/health")
async def health_check():
    """Health check endpoint - simplified for faster response"""
    try:
        memory_usage = MemoryManager.get_memory_usage()
        return {
            "status": "healthy",
            "memory_usage_mb": round(memory_usage, 2),
            "timestamp": "2024-01-01T00:00:00Z"
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e)
        }

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "message": "CV Analysis API",
        "version": "1.0.0",
        "endpoints": {
            "analyze_cv": "/analyze-cv",
            "analyze_jd": "/analyze-jd",
            "extract_personal_info": "/extract-personal-info",
            "health": "/health"
        }
    }

# Add new models for web client integration
class UserCVRequest(BaseModel):
    user_id: str
    cv_id: str
    job_category: str
    job_position: str = None

class JobPostingRequest(BaseModel):
    job_id: str
    job_title: str
    job_description: str
    job_requirements: str = None
    company_name: str = None

class WebClientAnalysisRequest(BaseModel):
    user_id: str
    cv_id: str
    job_id: str
    job_category: str
    job_position: str = None

@app.post("/analyze-cv-from-web-client")
async def analyze_cv_from_web_client(request: WebClientAnalysisRequest):
    """
    Ph√¢n t√≠ch CV t·ª´ web client - lu·ªìng m·ªõi
    CV v√† JD ƒë∆∞·ª£c import t·ª± ƒë·ªông t·ª´ web client
    """
    try:
        # Check memory usage before processing - but don't fail immediately
        memory_ok = check_memory_usage()
        if not memory_ok:
            logger.warning("High memory usage detected, but continuing...")
        
        # Lazy load analyzer - with better error handling
        try:
            analyzer = get_analyzer()
            if analyzer is None:
                raise HTTPException(
                    status_code=500,
                    detail="L·ªói server: Kh√¥ng th·ªÉ kh·ªüi t·∫°o analyzer"
                )
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o analyzer: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"L·ªói server: {str(e)}"
            )
        
        # 1. L·∫•y CV content t·ª´ web client database
        cv_content = await get_cv_content_from_web_client(request.user_id, request.cv_id)
        
        # 2. L·∫•y JD content t·ª´ web client database  
        jd_content = await get_jd_content_from_web_client(request.job_id)
        
        # 3. Ph√¢n t√≠ch CV v·ªõi JD
        analysis_result = analyzer.evaluate_cv_comprehensive(
            cv_text=cv_content,
            job_category=request.job_category,
            job_position=request.job_position,
            jd_text=jd_content,
            job_requirements=None  # C√≥ th·ªÉ th√™m t·ª´ JD content
        )
        # --- L∆∞u d·ªØ li·ªáu ƒë√£ tr√≠ch xu·∫•t (labeled) ---
        # L·∫•y th√¥ng tin ƒë√£ tr√≠ch xu·∫•t t·ª´ analysis_result
        cv_labeled = {
            "text": cv_content,
            "skills": analysis_result.get("cv_skills"),
            "education": analysis_result.get("education"),
            "projects": analysis_result.get("projects"),
            "experience": analysis_result.get("experience"),
        }
        jd_labeled = {
            "text": jd_content,
            "skills": analysis_result.get("jd_skills")
        }
        save_labeled_data(cv_labeled, jd_labeled)
        # --- End l∆∞u d·ªØ li·ªáu ---
        # 4. L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o web client database
        await save_analysis_result_to_web_client(
            user_id=request.user_id,
            cv_id=request.cv_id,
            job_id=request.job_id,
            analysis_result=analysis_result
        )
        
        # Clean up memory
        MemoryManager.force_garbage_collection()
        
        return analysis_result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"L·ªói khi ph√¢n t√≠ch CV t·ª´ web client: {str(e)}\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói server: {str(e)}"
        )

@app.get("/get-user-cv/{user_id}/{cv_id}")
async def get_user_cv(user_id: str, cv_id: str):
    """
    L·∫•y th√¥ng tin CV c·ªßa user t·ª´ web client
    """
    try:
        cv_info = await get_cv_info_from_web_client(user_id, cv_id)
        return cv_info
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y CV: {str(e)}")
        raise HTTPException(
            status_code=404,
            detail=f"Kh√¥ng t√¨m th·∫•y CV: {str(e)}"
        )

@app.get("/get-job-posting/{job_id}")
async def get_job_posting(job_id: str):
    """
    L·∫•y th√¥ng tin job posting t·ª´ web client
    """
    try:
        job_info = await get_job_info_from_web_client(job_id)
        return job_info
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y job posting: {str(e)}")
        raise HTTPException(
            status_code=404,
            detail=f"Kh√¥ng t√¨m th·∫•y job posting: {str(e)}"
        )

@app.post("/analyze-cv-with-job")
async def analyze_cv_with_job(request: UserCVRequest):
    """
    Ph√¢n t√≠ch CV v·ªõi job category ƒë∆∞·ª£c ch·ªçn
    CV ƒë∆∞·ª£c l·∫•y t·ª´ user account, JD ƒë∆∞·ª£c suggest t·ª± ƒë·ªông
    """
    try:
        # Check memory usage before processing - but don't fail immediately
        memory_ok = check_memory_usage()
        if not memory_ok:
            logger.warning("High memory usage detected, but continuing...")
        
        # Lazy load analyzer - with better error handling
        try:
            analyzer = get_analyzer()
            if analyzer is None:
                raise HTTPException(
                    status_code=500,
                    detail="L·ªói server: Kh√¥ng th·ªÉ kh·ªüi t·∫°o analyzer"
                )
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o analyzer: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"L·ªói server: {str(e)}"
            )
        
        # 1. L·∫•y CV content
        cv_content = await get_cv_content_from_web_client(request.user_id, request.cv_id)
        
        # 2. T√¨m job postings ph√π h·ª£p v·ªõi category
        suggested_jobs = await get_suggested_jobs_for_category(request.job_category)
        
        # 3. Ph√¢n t√≠ch v·ªõi t·ª´ng job suggestion
        analysis_results = []
        for job in suggested_jobs[:3]:  # Top 3 suggestions
            jd_content = await get_jd_content_from_web_client(job['job_id'])
            
            analysis_result = analyzer.evaluate_cv_comprehensive(
                cv_text=cv_content,
                job_category=request.job_category,
                job_position=request.job_position or job.get('job_title'),
                jd_text=jd_content
            )
            
            analysis_results.append({
                "job_id": job['job_id'],
                "job_title": job['job_title'],
                "company_name": job.get('company_name'),
                "analysis": analysis_result
            })
        
        return {
            "user_id": request.user_id,
            "cv_id": request.cv_id,
            "job_category": request.job_category,
            "suggested_analyses": analysis_results
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"L·ªói khi ph√¢n t√≠ch CV v·ªõi job suggestions: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"L·ªói server: {str(e)}"
        )

# Import web client integration
from ml_architecture.services.web_client_integration import WebClientIntegration, MockWebClientIntegration, save_labeled_data

# Initialize web client integration
web_client = MockWebClientIntegration()  # Use mock for development

# Helper functions for web client integration
async def get_cv_content_from_web_client(user_id: str, cv_id: str) -> str:
    """
    L·∫•y CV content t·ª´ web client database
    """
    logger.info(f"Getting CV content for user {user_id}, CV {cv_id}")
    return await web_client.get_cv_content(user_id, cv_id)

async def get_jd_content_from_web_client(job_id: str) -> str:
    """
    L·∫•y JD content t·ª´ web client database
    """
    logger.info(f"Getting JD content for job {job_id}")
    job_data = await web_client.get_job_content(job_id)
    return job_data.get('job_description', '') + '\n\n' + job_data.get('job_requirements', '')

async def get_cv_info_from_web_client(user_id: str, cv_id: str) -> dict:
    """
    L·∫•y th√¥ng tin CV t·ª´ web client
    """
    user_cvs = await web_client.get_user_cvs(user_id)
    for cv in user_cvs:
        if cv.get('cv_id') == cv_id:
            return cv
    return {}

async def get_job_info_from_web_client(job_id: str) -> dict:
    """
    L·∫•y th√¥ng tin job posting t·ª´ web client
    """
    return await web_client.get_job_content(job_id)

async def get_suggested_jobs_for_category(job_category: str) -> list:
    """
    L·∫•y danh s√°ch job suggestions cho category
    """
    return await web_client.get_jobs_by_category(job_category)

async def save_analysis_result_to_web_client(user_id: str, cv_id: str, job_id: str, analysis_result: dict):
    """
    L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o web client database
    """
    logger.info(f"Saving analysis result for user {user_id}, CV {cv_id}, job {job_id}")
    return await web_client.save_analysis_result(user_id, cv_id, job_id, analysis_result)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 