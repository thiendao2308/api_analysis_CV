import spacy
import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import re
import os

class JDAnalysisSystem:
    """
    B∆Ø·ªöC 2: Tr√≠ch xu·∫•t y√™u c·∫ßu t·ª´ JD (NLP/NER model)
    H·ªá th·ªëng ph√¢n t√≠ch JD v√† tr√≠ch xu·∫•t skills requirements
    """
    def __init__(self, model_path="model_full/model-best"):
        """Kh·ªüi t·∫°o h·ªá th·ªëng ph√¢n t√≠ch JD - B∆Ø·ªöC 2"""
        try:
            # S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi
            abs_model_path = os.path.join(os.path.dirname(__file__), model_path)
            self.nlp = spacy.load(abs_model_path)
            print(f"‚úÖ B∆Ø·ªöC 2: ƒê√£ load model: {abs_model_path}")
        except OSError:
            try:
                # Fallback sang model c≈©
                abs_model_path = os.path.join(os.path.dirname(__file__), "model", "model-best")
                self.nlp = spacy.load(abs_model_path)
                print(f"‚úÖ B∆Ø·ªöC 2: ƒê√£ load model fallback: {abs_model_path}")
            except OSError:
                print(f"‚ùå B∆Ø·ªöC 2: Kh√¥ng th·ªÉ load model t·ª´ {model_path}")
                print("S·ª≠ d·ª•ng model m·∫∑c ƒë·ªãnh...")
                try:
                    self.nlp = spacy.load("en_core_web_sm")
                except:
                    print("‚ùå B∆Ø·ªöC 2: Kh√¥ng c√≥ model n√†o kh·∫£ d·ª•ng!")
                    self.nlp = None
    
    def extract_skills_from_jd(self, jd_text):
        """B∆Ø·ªöC 2: Tr√≠ch xu·∫•t skills t·ª´ JD s·ª≠ d·ª•ng NER model"""
        if not self.nlp:
            return []
        
        try:
            doc = self.nlp(jd_text)
            skills = []
            
            for ent in doc.ents:
                if ent.label_ == "SKILL":
                    skill_text = ent.text.strip()
                    if skill_text and len(skill_text) > 1:
                        skills.append(skill_text)
            
            return list(set(skills))  # Lo·∫°i b·ªè duplicates
        except Exception as e:
            print(f"‚ùå B∆Ø·ªöC 2: L·ªói khi tr√≠ch xu·∫•t skills t·ª´ JD: {e}")
            return []
    
    def analyze_single_jd(self, jd_text):
        """B∆Ø·ªöC 2: Ph√¢n t√≠ch m·ªôt JD ƒë∆°n l·∫ª"""
        print("=== B∆Ø·ªöC 2: PH√ÇN T√çCH JD ===")
        print(f"JD: {jd_text[:200]}...")
        
        # Tr√≠ch xu·∫•t skills
        skills = self.extract_skills_from_jd(jd_text)
        
        print(f"\nüìã Skills t√¨m th·∫•y ({len(skills)}):")
        for i, skill in enumerate(skills, 1):
            print(f"  {i}. {skill}")
        
        # Ph√¢n t√≠ch lo·∫°i skills
        skill_categories = self.categorize_skills(skills)
        
        print(f"\nüìä Ph√¢n lo·∫°i skills:")
        for category, skills_list in skill_categories.items():
            if skills_list:
                print(f"  {category}: {', '.join(skills_list)}")
        
        return {
            'skills': skills,
            'skill_count': len(skills),
            'categories': skill_categories
        }
    
    def categorize_skills(self, skills):
        """Ph√¢n lo·∫°i skills th√†nh c√°c nh√≥m"""
        categories = {
            'Programming Languages': [],
            'Frameworks & Libraries': [],
            'Databases': [],
            'Cloud & DevOps': [],
            'Soft Skills': [],
            'Tools & Platforms': [],
            'Other': []
        }
        
        # ƒê·ªãnh nghƒ©a t·ª´ kh√≥a cho t·ª´ng category
        keywords = {
            'Programming Languages': ['python', 'java', 'javascript', 'c++', 'c#', 'php', 'ruby', 'go', 'rust', 'swift', 'kotlin', 'scala'],
            'Frameworks & Libraries': ['react', 'angular', 'vue', 'node.js', 'django', 'flask', 'spring', 'express', 'jquery', 'bootstrap', 'tensorflow', 'pytorch'],
            'Databases': ['mysql', 'postgresql', 'mongodb', 'redis', 'oracle', 'sql server', 'sqlite', 'elasticsearch'],
            'Cloud & DevOps': ['aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git', 'ci/cd', 'terraform', 'ansible'],
            'Soft Skills': ['communication', 'leadership', 'teamwork', 'problem solving', 'analytical', 'creativity', 'time management'],
            'Tools & Platforms': ['jira', 'confluence', 'slack', 'teams', 'figma', 'adobe', 'excel', 'powerpoint', 'word']
        }
        
        for skill in skills:
            skill_lower = skill.lower()
            categorized = False
            
            for category, keyword_list in keywords.items():
                if any(keyword in skill_lower for keyword in keyword_list):
                    categories[category].append(skill)
                    categorized = True
                    break
            
            if not categorized:
                categories['Other'].append(skill)
        
        return categories
    
    def analyze_multiple_jds(self, jd_list):
        """B∆Ø·ªöC 2: Ph√¢n t√≠ch nhi·ªÅu JD"""
        print("=== B∆Ø·ªöC 2: PH√ÇN T√çCH NHI·ªÄU JD ===")
        
        all_skills = []
        all_categories = []
        
        for i, jd in enumerate(jd_list):
            print(f"\nJD {i+1}:")
            result = self.analyze_single_jd(jd)
            all_skills.extend(result['skills'])
            all_categories.append(result['categories'])
        
        # Th·ªëng k√™ t·ªïng h·ª£p
        skill_counts = Counter(all_skills)
        
        print(f"\nüìà TH·ªêNG K√ä T·ªîNG H·ª¢P:")
        print(f"T·ªïng s·ªë skills: {len(all_skills)}")
        print(f"S·ªë skills unique: {len(skill_counts)}")
        
        print(f"\nüèÜ TOP 10 SKILLS PH·ªî BI·∫æN:")
        for skill, count in skill_counts.most_common(10):
            print(f"  {skill}: {count} l·∫ßn")
        
        return {
            'all_skills': all_skills,
            'skill_counts': skill_counts,
            'all_categories': all_categories
        }
    
    def analyze_jd_file(self, file_path):
        """B∆Ø·ªöC 2: Ph√¢n t√≠ch file CSV ch·ª©a JD"""
        print(f"=== B∆Ø·ªöC 2: PH√ÇN T√çCH FILE: {file_path} ===")
        
        # ƒê·ªçc file
        try:
            df = pd.read_csv(file_path)
            if 'text' not in df.columns:
                df.columns = ['text']
        except:
            df = pd.read_csv(file_path, header=None, names=['text'])
        
        print(f"T·ªïng s·ªë JD: {len(df)}")
        
        # Ph√¢n t√≠ch t·ª´ng JD
        all_skills = []
        skill_counts = Counter()
        
        for idx, row in df.iterrows():
            jd_text = row['text']
            skills = self.extract_skills_from_jd(jd_text)
            all_skills.extend(skills)
            skill_counts.update(skills)
            
            if (idx + 1) % 100 == 0:
                print(f"ƒê√£ ph√¢n t√≠ch {idx + 1}/{len(df)} JD...")
        
        # T·∫°o b√°o c√°o
        self.generate_report(skill_counts, len(df))
        
        return {
            'total_jds': len(df),
            'total_skills': len(all_skills),
            'unique_skills': len(skill_counts),
            'skill_counts': skill_counts
        }
    
    def generate_report(self, skill_counts, total_jds):
        """T·∫°o b√°o c√°o ph√¢n t√≠ch"""
        print(f"\nüìä B√ÅO C√ÅO PH√ÇN T√çCH:")
        print(f"T·ªïng s·ªë JD: {total_jds:,}")
        print(f"T·ªïng s·ªë skills: {sum(skill_counts.values()):,}")
        print(f"S·ªë skills unique: {len(skill_counts):,}")
        print(f"Trung b√¨nh skills/JD: {sum(skill_counts.values())/total_jds:.1f}")
        
        print(f"\nüèÜ TOP 20 SKILLS PH·ªî BI·∫æN:")
        for skill, count in skill_counts.most_common(20):
            percentage = (count / total_jds) * 100
            print(f"  {skill}: {count:,} l·∫ßn ({percentage:.1f}%)")
    
    def find_similar_jds(self, target_jd, jd_list, top_k=5):
        """T√¨m JD t∆∞∆°ng t·ª±"""
        print("=== B∆Ø·ªöC 2: T√åM JD T∆Ø∆†NG T·ª∞ ===")
        
        # Tr√≠ch xu·∫•t skills c·ªßa target JD
        target_skills = set(self.extract_skills_from_jd(target_jd))
        
        similarities = []
        
        for i, jd in enumerate(jd_list):
            jd_skills = set(self.extract_skills_from_jd(jd))
            
            # T√≠nh Jaccard similarity
            if target_skills or jd_skills:
                intersection = len(target_skills.intersection(jd_skills))
                union = len(target_skills.union(jd_skills))
                similarity = intersection / union if union > 0 else 0
                similarities.append((i, similarity, jd_skills))
        
        # S·∫Øp x·∫øp theo similarity
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        print(f"\nüèÜ TOP {top_k} JD T∆Ø∆†NG T·ª∞:")
        for i, (jd_idx, similarity, skills) in enumerate(similarities[:top_k]):
            print(f"  {i+1}. JD {jd_idx+1}: {similarity:.2f} ({len(skills)} skills)")
        
        return similarities[:top_k]

# Test function
if __name__ == "__main__":
    # Test v·ªõi JD m·∫´u
    jd_analyzer = JDAnalysisSystem()
    
    sample_jd = """
    We are looking for a Senior Python Developer with experience in:
    - Python programming
    - Django framework
    - PostgreSQL database
    - AWS cloud services
    - Docker containerization
    - Git version control
    """
    
    result = jd_analyzer.analyze_single_jd(sample_jd)
    print(f"\nK·∫øt qu·∫£ ph√¢n t√≠ch:")
    print(f"Skills: {result['skills']}")
    print(f"Categories: {result['categories']}") 