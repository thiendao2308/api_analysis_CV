import logging
import openai
import os
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class SpellError:
    """Th√¥ng tin v·ªÅ l·ªói ch√≠nh t·∫£/ƒë·ªãnh d·∫°ng"""
    word: str
    line_number: int
    error_type: str  # "spelling" ho·∫∑c "formatting"
    suggestion: str
    context: str
    severity: str  # "low", "medium", "high"

@dataclass
class SpellCheckResult:
    """K·∫øt qu·∫£ ki·ªÉm tra ch√≠nh t·∫£"""
    total_errors: int
    spelling_errors: int
    formatting_errors: int
    errors: List[SpellError]
    overall_score: float  # 0-100
    suggestions: List[str]
    summary: str

class CVSpellChecker:
    """Ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng cho CV s·ª≠ d·ª•ng LLM"""

    def __init__(self):
        self.client = None
        self._init_openai_client()

        # T·ª´ ƒëi·ªÉn ti·∫øng Vi·ªát c∆° b·∫£n ƒë·ªÉ fallback
        self.vietnamese_words = {
            "nguy·ªÖn", "tr·∫ßn", "l√™", "ph·∫°m", "ho√†ng", "hu·ª≥nh", "phan", "v≈©", "v√µ",
            "ƒë·∫∑ng", "b√πi", "ƒë·ªó", "h·ªì", "ng√¥", "d∆∞∆°ng", "l√Ω", "ƒëinh", "t√¥", "l√¢m",
            "tr·ªãnh", "ƒëo√†n", "ph√πng", "ki·ªÅu", "cao", "t·∫°", "h√†", "tƒÉng", "l∆∞u",
            "t·ªëng", "ch√¢u", "t·ª´", "h·ª©a", "h·ªìng", "minh", "th√†nh", "c√¥ng", "thi·ªán",
            "th·ªã", "vƒÉn", "ƒë·ª©c", "quang", "huy", "tu·∫•n", "d≈©ng", "h√πng", "nam",
            "developer", "engineer", "programmer", "analyst", "manager", "specialist",
            "javascript", "python", "java", "csharp", "react", "angular", "vue",
            "nodejs", "express", "django", "aspnet", "sql", "mongodb", "docker",
            "aws", "azure", "git", "github", "agile", "scrum", "kanban"
        }

    def _init_openai_client(self):
        """Kh·ªüi t·∫°o OpenAI client"""
        try:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.client = openai.OpenAI(api_key=api_key)
                logger.info("‚úÖ OpenAI client initialized for spell checking")
            else:
                logger.warning("‚ö†Ô∏è OPENAI_API_KEY not found for spell checking")
        except Exception as e:
            logger.error(f"‚ùå Error initializing OpenAI client for spell checking: {e}")

    def check_cv_spelling(self, cv_text: str) -> SpellCheckResult:
        """Ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng cho CV"""
        try:
            if not self.client:
                logger.warning("‚ö†Ô∏è OpenAI client not available, using fallback spell checking")
                return self._fallback_spell_check(cv_text)

            # T·∫°o prompt cho LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£
            prompt = self._create_spell_check_prompt(cv_text)

            # G·ªçi OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "B·∫°n l√† m·ªôt chuy√™n gia ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng ti·∫øng Vi·ªát v√† ti·∫øng Anh. H√£y ki·ªÉm tra CV v√† t√¨m ra c√°c l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng. Tr·∫£ v·ªÅ k·∫øt qu·∫£ theo format JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=1000
            )

            # X·ª≠ l√Ω response t·ª´ LLM
            llm_response = response.choices[0].message.content
            logger.info(f"ü§ñ LLM Spell Check Response: {llm_response}")

            # Parse k·∫øt qu·∫£ t·ª´ LLM
            spell_check_result = self._parse_llm_spell_check_response(llm_response, cv_text)

            if spell_check_result.total_errors > 0:
                logger.info(f"‚úÖ LLM found {spell_check_result.total_errors} errors in CV")
            else:
                logger.info("‚úÖ LLM found no errors in CV")

            return spell_check_result

        except Exception as e:
            logger.error(f"‚ùå Error in LLM spell checking: {e}")
            return self._fallback_spell_check(cv_text)

    def _create_spell_check_prompt(self, cv_text: str) -> str:
        """T·∫°o prompt cho LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£"""
        # L·∫•y 30 d√≤ng ƒë·∫ßu ƒë·ªÉ gi·∫£m token usage
        lines = cv_text.split('\n')
        cv_preview = '\n'.join(lines[:30])

        prompt = f"""
H√£y ki·ªÉm tra ch√≠nh t·∫£ t·ª´ ng·ªØ v√† ƒë·ªãnh d·∫°ng c·ªßa CV sau ƒë√¢y:

CV TEXT:
{cv_preview}

Y√™u c·∫ßu ki·ªÉm tra:
1. L·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát v√† ti·∫øng Anh (spelling) - ch·ªâ nh·ªØng t·ª´ th·ª±c s·ª± sai ch√≠nh t·∫£
2. L·ªói ƒë·ªãnh d·∫°ng (formatting) - kho·∫£ng tr·∫Øng th·ª´a, cƒÉn l·ªÅ sai, vi·∫øt hoa kh√¥ng nh·∫•t qu√°n

L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG b√°o l·ªói cho t√™n ri√™ng, t√™n c√¥ng ty, t√™n c√¥ng ngh·ªá ƒë√∫ng
- KH√îNG b√°o l·ªói cho "Backend Developer", "Frontend Developer" - ƒë√¢y l√† t√™n v·ªã tr√≠ ƒë√∫ng
- KH√îNG b√°o l·ªói cho "AI/LLM", "ASP.NET" - ƒë√¢y l√† t√™n c√¥ng ngh·ªá ƒë√∫ng
- Ch·ªâ b√°o l·ªói cho nh·ªØng t·ª´ th·ª±c s·ª± sai ch√≠nh t·∫£ ho·∫∑c ƒë·ªãnh d·∫°ng r√µ r√†ng sai
- TR∆Ø·ªúNG "context" PH·∫¢I VI·∫æT B·∫∞NG TI·∫æNG VI·ªÜT

H√£y tr·∫£ v·ªÅ k·∫øt qu·∫£ theo format JSON:
{{
    "total_errors": s·ªë_l·ªói_t·ªïng,
    "spelling_errors": s·ªë_l·ªói_ch√≠nh_t·∫£_th·ª±c_s·ª±,
    "formatting_errors": s·ªë_l·ªói_ƒë·ªãnh_d·∫°ng_th·ª±c_s·ª±,
    "errors": [
        {{
            "word": "t·ª´_sai_th·ª±c_s·ª±",
            "line_number": s·ªë_d√≤ng,
            "error_type": "spelling_ho·∫∑c_formatting",
            "suggestion": "g·ª£i_√Ω_s·ª≠a",
            "context": "ng·ªØ_c·∫£nh_b·∫±ng_ti·∫øng_vi·ªát",
            "severity": "m·ª©c_ƒë·ªô_nghi√™m_tr·ªçng"
        }}
    ],
    "overall_score": ƒëi·ªÉm_t·ªïng_quan_0_100,
    "suggestions": ["g·ª£i_√Ω_1", "g·ª£i_√Ω_2"],
    "summary": "t√≥m_t·∫Øt_k·∫øt_qu·∫£_b·∫±ng_ti·∫øng_vi·ªát"
}}

V√≠ d·ª• context ti·∫øng Vi·ªát:
- "T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ k·ªπ nƒÉng"
- "T√™n v·ªã tr√≠ c√¥ng vi·ªác c·∫ßn vi·∫øt hoa ƒë√∫ng c√°ch"
- "T√™n c√¥ng ngh·ªá c·∫ßn vi·∫øt ƒë√∫ng ch√≠nh t·∫£"
- "Ph·∫ßn m√¥ t·∫£ d·ª± √°n c√≥ l·ªói ƒë·ªãnh d·∫°ng"

Ti√™u ch√≠ ƒë√°nh gi√°:
- ƒêi·ªÉm 90-100: Ho√†n h·∫£o ho·∫∑c ch·ªâ c√≥ 1-2 l·ªói nh·ªè
- ƒêi·ªÉm 70-89: Kh√° t·ªët, c√≥ m·ªôt s·ªë l·ªói nh·ªè
- ƒêi·ªÉm 50-69: Trung b√¨nh, c√≥ nhi·ªÅu l·ªói
- ƒêi·ªÉm 0-49: K√©m, c√≥ nhi·ªÅu l·ªói nghi√™m tr·ªçng
"""
        return prompt

    def _parse_llm_spell_check_response(self, llm_response: str, cv_text: str) -> SpellCheckResult:
        """Parse response t·ª´ LLM cho spell checking"""
        try:
            import json
            import re

            # T√¨m JSON trong response
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)

                # Parse errors
                errors = []
                for error_data in data.get('errors', []):
                    error = SpellError(
                        word=error_data.get('word', ''),
                        line_number=error_data.get('line_number', 0),
                        error_type=error_data.get('error_type', 'spelling'),
                        suggestion=error_data.get('suggestion', ''),
                        context=error_data.get('context', ''),
                        severity=error_data.get('severity', 'medium')
                    )
                    errors.append(error)

                return SpellCheckResult(
                    total_errors=data.get('total_errors', 0),
                    spelling_errors=data.get('spelling_errors', 0),
                    formatting_errors=data.get('formatting_errors', 0),
                    errors=errors,
                    overall_score=data.get('overall_score', 100),
                    suggestions=data.get('suggestions', []),
                    summary=data.get('summary', 'Kh√¥ng c√≥ l·ªói ch√≠nh t·∫£')
                )

            # Fallback: parse t·ª´ text response
            return self._extract_from_text_response(llm_response, cv_text)

        except Exception as e:
            logger.error(f"‚ùå Error parsing LLM spell check response: {e}")
            return self._extract_from_text_response(llm_response, cv_text)

    def _extract_from_text_response(self, llm_response: str, cv_text: str) -> SpellCheckResult:
        """Tr√≠ch xu·∫•t th√¥ng tin t·ª´ text response n·∫øu JSON parse th·∫•t b·∫°i"""
        try:
            lines = llm_response.split('\n')
            errors = []
            total_errors = 0

            # T√¨m th√¥ng tin v·ªÅ l·ªói trong text response
            for line in lines:
                line_lower = line.lower()

                if 'l·ªói' in line_lower or 'error' in line_lower:
                    if ':' in line:
                        error_part = line.split(':')[1].strip()
                        if error_part.isdigit():
                            total_errors = int(error_part)

                if 'ƒëi·ªÉm' in line_lower or 'score' in line_lower:
                    if ':' in line:
                        score_part = line.split(':')[1].strip()
                        try:
                            score = float(re.findall(r'\d+', score_part)[0])
                        except:
                            score = 100

            # T·∫°o k·∫øt qu·∫£ fallback v·ªõi context ti·∫øng Vi·ªát
            return SpellCheckResult(
                total_errors=total_errors,
                spelling_errors=total_errors // 2,
                formatting_errors=total_errors // 2,
                errors=errors,
                overall_score=score if 'score' in locals() else 100,
                suggestions=["Ki·ªÉm tra l·∫°i ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng"],
                summary=f"T√¨m th·∫•y {total_errors} l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng trong CV"
            )

        except Exception as e:
            logger.error(f"‚ùå Error extracting from text response: {e}")
            return SpellCheckResult(
                total_errors=0,
                spelling_errors=0,
                formatting_errors=0,
                errors=[],
                overall_score=100,
                suggestions=["Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"],
                summary="Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"
            )

    def _fallback_spell_check(self, cv_text: str) -> SpellCheckResult:
        """Fallback spell checking khi LLM kh√¥ng kh·∫£ d·ª•ng"""
        try:
            lines = cv_text.split('\n')
            errors = []
            total_errors = 0

            # Danh s√°ch t·ª´ ƒë√∫ng kh√¥ng ƒë∆∞·ª£c b√°o l·ªói
            correct_terms = {
                "backend", "frontend", "fullstack", "developer", "engineer", "programmer",
                "javascript", "python", "java", "csharp", "react", "angular", "vue",
                "nodejs", "express", "django", "aspnet", "sql", "mongodb", "docker",
                "aws", "azure", "git", "github", "agile", "scrum", "kanban",
                "ai", "llm", "machine learning", "deep learning", "neural network",
                "information technology", "software technology", "computer science"
            }

            # Ki·ªÉm tra c∆° b·∫£n: t√¨m t·ª´ c√≥ th·ªÉ sai ch√≠nh t·∫£
            for i, line in enumerate(lines):
                line_lower = line.lower()
                words = line.split()

                for word in words:
                    # Lo·∫°i b·ªè d·∫•u c√¢u v√† s·ªë
                    clean_word = re.sub(r'[^\w\s]', '', word)

                    if len(clean_word) > 2:
                        # Ki·ªÉm tra t·ª´ ti·∫øng Vi·ªát c∆° b·∫£n
                        if not any(vn_word in clean_word.lower() for vn_word in self.vietnamese_words):
                            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† t√™n ri√™ng ho·∫∑c t·ª´ ƒë√∫ng kh√¥ng
                            if not self._is_proper_noun(clean_word) and clean_word.lower() not in correct_terms:
                                # Ki·ªÉm tra th√™m: kh√¥ng b√°o l·ªói cho c√°c t·ª´ c√≥ th·ªÉ ƒë√∫ng
                                if not self._is_likely_correct(clean_word, line):
                                    # T·∫°o context ti·∫øng Vi·ªát d·ª±a tr√™n ng·ªØ c·∫£nh
                                    context_vn = self._create_vietnamese_context(line, i + 1)
                                    
                                    # C√≥ th·ªÉ l√† l·ªói ch√≠nh t·∫£
                                    error = SpellError(
                                        word=word,
                                        line_number=i + 1,
                                        error_type="spelling",
                                        suggestion=f"Ki·ªÉm tra l·∫°i t·ª´ '{word}'",
                                        context=context_vn,
                                        severity="low"
                                    )
                                    errors.append(error)
                                    total_errors += 1

            # T√≠nh ƒëi·ªÉm d·ª±a tr√™n s·ªë l·ªói
            if total_errors == 0:
                overall_score = 100
            elif total_errors <= 2:
                overall_score = 95
            elif total_errors <= 5:
                overall_score = 85
            elif total_errors <= 10:
                overall_score = 75
            else:
                overall_score = 65

            return SpellCheckResult(
                total_errors=total_errors,
                spelling_errors=total_errors,
                formatting_errors=0,
                errors=errors,
                overall_score=overall_score,
                suggestions=["S·ª≠ d·ª•ng LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£ ch√≠nh x√°c h∆°n"],
                summary=f"Fallback check: T√¨m th·∫•y {total_errors} l·ªói ch√≠nh t·∫£"
            )

        except Exception as e:
            logger.error(f"‚ùå Error in fallback spell checking: {e}")
            return SpellCheckResult(
                total_errors=0,
                spelling_errors=0,
                formatting_errors=0,
                errors=[],
                overall_score=100,
                suggestions=["Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"],
                summary="Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"
            )

    def _is_proper_noun(self, word: str) -> bool:
        """Ki·ªÉm tra xem t·ª´ c√≥ ph·∫£i l√† danh t·ª´ ri√™ng kh√¥ng"""
        # Danh t·ª´ ri√™ng th∆∞·ªùng vi·∫øt hoa
        if word[0].isupper() and len(word) > 2:
            return True

        # T√™n c√¥ng ty, c√¥ng ngh·ªá ph·ªï bi·∫øn
        tech_terms = {
            "microsoft", "google", "facebook", "amazon", "apple", "netflix",
            "react", "angular", "vue", "node", "python", "java", "javascript",
            "html", "css", "sql", "mongodb", "docker", "kubernetes", "aws",
            "azure", "github", "gitlab", "bitbucket", "jira", "confluence"
        }

        if word.lower() in tech_terms:
            return True

        return False

    def _is_likely_correct(self, word: str, context: str) -> bool:
        """Ki·ªÉm tra xem t·ª´ c√≥ kh·∫£ nƒÉng ƒë√∫ng kh√¥ng d·ª±a tr√™n ng·ªØ c·∫£nh"""
        word_lower = word.lower()
        context_lower = context.lower()
        
        # C√°c pattern cho t·ª´ c√≥ th·ªÉ ƒë√∫ng
        patterns = [
            r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b',  # Proper nouns like "Backend Developer"
            r'\b[A-Z]{2,}\b',  # Acronyms like "AI", "LLM", "API"
            r'\b[A-Za-z]+\.NET\b',  # .NET technologies
            r'\b[A-Za-z]+\.js\b',  # JavaScript frameworks
            r'\b[A-Za-z]+\.py\b',  # Python frameworks
        ]
        
        for pattern in patterns:
            if re.match(pattern, word):
                return True
        
        # Ki·ªÉm tra ng·ªØ c·∫£nh
        if any(tech in context_lower for tech in ['technology', 'framework', 'library', 'tool']):
            return True
            
        if any(company in context_lower for company in ['company', 'corporation', 'inc', 'ltd']):
            return True
            
        return False

    def _create_vietnamese_context(self, line: str, line_number: int) -> str:
        """T·∫°o context ti·∫øng Vi·ªát cho l·ªói ch√≠nh t·∫£"""
        line_lower = line.lower()
        
        # X√°c ƒë·ªãnh lo·∫°i n·ªôi dung d·ª±a tr√™n t·ª´ kh√≥a
        if any(word in line_lower for word in ['k·ªπ nƒÉng', 'skill', 'technology', 'framework']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ k·ªπ nƒÉng (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['v·ªã tr√≠', 'position', 'job', 'title']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ v·ªã tr√≠ c√¥ng vi·ªác (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['d·ª± √°n', 'project', 'description']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ d·ª± √°n (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['c√¥ng ty', 'company', 'organization']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn th√¥ng tin c√¥ng ty (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['h·ªçc v·∫•n', 'education', 'degree', 'school']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn th√¥ng tin h·ªçc v·∫•n (d√≤ng {line_number})"
        else:
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong n·ªôi dung CV (d√≤ng {line_number})"
