import logging
import openai
import os
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class SpellError:
    """Th√¥ng tin v·ªÅ l·ªói ch√≠nh t·∫£/ƒë·ªãnh d·∫°ng"""
    word: str
    line_number: int
    error_type: str  # "spelling" ho·∫∑c "formatting"
    suggestion: str
    context: str
    severity: str  # "low", "medium", "high"

@dataclass
class SpellCheckResult:
    """K·∫øt qu·∫£ ki·ªÉm tra ch√≠nh t·∫£"""
    total_errors: int
    spelling_errors: int
    formatting_errors: int
    errors: List[SpellError]
    overall_score: float  # 0-100
    suggestions: List[str]
    summary: str

class CVSpellChecker:
    """Ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng cho CV s·ª≠ d·ª•ng LLM"""

    def __init__(self):
        self.client = None
        self._init_openai_client()

        # T·ª´ ƒëi·ªÉn ti·∫øng Vi·ªát c∆° b·∫£n ƒë·ªÉ fallback
        self.vietnamese_words = {
            "nguy·ªÖn", "tr·∫ßn", "l√™", "ph·∫°m", "ho√†ng", "hu·ª≥nh", "phan", "v≈©", "v√µ",
            "ƒë·∫∑ng", "b√πi", "ƒë·ªó", "h·ªì", "ng√¥", "d∆∞∆°ng", "l√Ω", "ƒëinh", "t√¥", "l√¢m",
            "tr·ªãnh", "ƒëo√†n", "ph√πng", "ki·ªÅu", "cao", "t·∫°", "h√†", "tƒÉng", "l∆∞u",
            "t·ªëng", "ch√¢u", "t·ª´", "h·ª©a", "h·ªìng", "minh", "th√†nh", "c√¥ng", "thi·ªán",
            "th·ªã", "vƒÉn", "ƒë·ª©c", "quang", "huy", "tu·∫•n", "d≈©ng", "h√πng", "nam",
            "developer", "engineer", "programmer", "analyst", "manager", "specialist",
            "javascript", "python", "java", "csharp", "react", "angular", "vue",
            "nodejs", "express", "django", "aspnet", "sql", "mongodb", "docker",
            "aws", "azure", "git", "github", "agile", "scrum", "kanban"
        }

    def _init_openai_client(self):
        """Kh·ªüi t·∫°o OpenAI client"""
        try:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.client = openai.OpenAI(api_key=api_key)
                logger.info("‚úÖ OpenAI client initialized for spell checking")
            else:
                logger.warning("‚ö†Ô∏è OPENAI_API_KEY not found for spell checking")
        except Exception as e:
            logger.error(f"‚ùå Error initializing OpenAI client for spell checking: {e}")

    def check_cv_spelling(self, cv_text: str) -> SpellCheckResult:
        """Ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng cho CV"""
        try:
            if not self.client:
                logger.warning("‚ö†Ô∏è OpenAI client not available, using fallback spell checking")
                return self._fallback_spell_check(cv_text)

            # T·∫°o prompt cho LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£
            prompt = self._create_spell_check_prompt(cv_text)

            # G·ªçi OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "B·∫°n l√† chuy√™n gia ki·ªÉm tra ch√≠nh t·∫£ v√† kho·∫£ng tr·∫Øng sau d·∫•u (',', '.', ';', ':') cho CV. Ch·ªâ ki·ªÉm tra 2 h·∫°ng m·ª•c: ch√≠nh t·∫£ (ti·∫øng Vi·ªát/ti·∫øng Anh) v√† kho·∫£ng tr·∫Øng sau d·∫•u. KH√îNG ki·ªÉm tra ng·ªØ ph√°p, d·∫•u c√¢u kh√°c, vi·∫øt hoa, cƒÉn l·ªÅ. Tr·∫£ v·ªÅ JSON nh∆∞ h∆∞·ªõng d·∫´n."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=1000
            )

            # X·ª≠ l√Ω response t·ª´ LLM
            llm_response = response.choices[0].message.content
            logger.info(f"ü§ñ LLM Spell Check Response: {llm_response}")

            # Parse k·∫øt qu·∫£ t·ª´ LLM
            spell_check_result = self._parse_llm_spell_check_response(llm_response, cv_text)

            if spell_check_result.total_errors > 0:
                logger.info(f"‚úÖ LLM found {spell_check_result.total_errors} errors in CV")
            else:
                logger.info("‚úÖ LLM found no errors in CV")

            return spell_check_result

        except Exception as e:
            logger.error(f"‚ùå Error in LLM spell checking: {e}")
            return self._fallback_spell_check(cv_text)

    def _create_spell_check_prompt(self, cv_text: str) -> str:
        """T·∫°o prompt cho LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£"""
        # L·∫•y 30 d√≤ng ƒë·∫ßu ƒë·ªÉ gi·∫£m token usage
        lines = cv_text.split('\n')
        cv_preview = '\n'.join(lines[:30])

        # Ghi ƒë√® b·∫±ng template an to√†n, tr√°nh f-string v·ªõi d·∫•u ngo·∫∑c nh·ªçn
        prompt_template = """
H√£y ch·ªâ ki·ªÉm tra 2 h·∫°ng m·ª•c sau trong CV d∆∞·ªõi ƒë√¢y v√† KH√îNG ki·ªÉm tra ti√™u ch√≠ n√†o kh√°c:

CV TEXT:
<<CV_PREVIEW>>

I. CH√çNH T·∫¢ (spelling):
- N·∫øu CV l√† ti·∫øng Anh: ch·ªâ ki·ªÉm tra t·ª´ ti·∫øng Anh c√≥ vi·∫øt ƒë√∫ng ch√≠nh t·∫£ t·ª´ ƒëi·ªÉn hay kh√¥ng.
- N·∫øu CV l√† ti·∫øng Vi·ªát: ch·ªâ ki·ªÉm tra l·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát. Gi·ªØ nguy√™n d·∫•u ti·∫øng Vi·ªát, tuy·ªát ƒë·ªëi KH√îNG g·ª£i √Ω b·ªè d·∫•u.
- V√≠ d·ª•: "Flulter" -> "Flutter"; "tooi" -> "toi" (n·∫øu vƒÉn b·∫£n kh√¥ng d·∫•u) ho·∫∑c "tooi" -> "t√¥i" (n·∫øu vƒÉn b·∫£n c√≥ d·∫•u).
- KH√îNG b√°o l·ªói cho: t√™n ri√™ng, t√™n c√¥ng ty, job title h·ª£p l·ªá ("Backend Developer", "Frontend Developer"), acronym/vi·∫øt t·∫Øt ƒë√∫ng ("AI/LLM", "API", "ASP.NET").

II. ƒê·ªäNH D·∫†NG (formatting - CH·ªà kho·∫£ng tr·∫Øng sau d·∫•u):
- Ch·ªâ ki·ªÉm tra kho·∫£ng tr·∫Øng SAU c√°c d·∫•u: "," "." ";" ":".
- Quy t·∫Øc: n·∫øu sau c√°c d·∫•u tr√™n c√≤n k√Ω t·ª± ch·ªØ ti·∫øp theo th√¨ PH·∫¢I c√≥ ƒë√∫ng 1 d·∫•u c√°ch.
- Ngo·∫°i l·ªá kh√¥ng b√°o l·ªói:
  + D·∫•u ·ªü cu·ªëi d√≤ng.
  + S·ªë th·∫≠p ph√¢n: v√≠ d·ª• "3.14".
  + Ph√¢n t√°ch h√†ng ngh√¨n: v√≠ d·ª• "1,000".
- KH√îNG ki·ªÉm tra/c·∫£nh b√°o c√°c ƒë·ªãnh d·∫°ng kh√°c (vi·∫øt hoa, cƒÉn l·ªÅ, ch·∫•m c√¢u kh√°c, bullet, tab, v.v.).

L∆ØU √ù QUAN TR·ªåNG:
- KH√îNG b√°o l·ªói ho·∫∑c ƒë·ªÅ xu·∫•t thay ƒë·ªïi v·ªõi t√™n ri√™ng ti·∫øng Vi·ªát c√≥ d·∫•u (v√≠ d·ª•: "ƒê√†o" l√† ƒë√∫ng, kh√¥ng g·ª£i √Ω "Dao").
- KH√îNG g·ª£i √Ω thay ƒë·ªïi v·ªõi job title ho·∫∑c thu·∫≠t ng·ªØ c√¥ng ngh·ªá ƒë√∫ng.
- TR∆Ø·ªúNG "context" v√† "summary" PH·∫¢I VI·∫æT B·∫∞NG TI·∫æNG VI·ªÜT, ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu.

H√£y tr·∫£ v·ªÅ k·∫øt qu·∫£ theo format JSON:
{
    "total_errors": s·ªë_l·ªói_t·ªïng,
    "spelling_errors": s·ªë_l·ªói_ch√≠nh_t·∫£,
    "formatting_errors": s·ªë_l·ªói_kho·∫£ng_tr·∫Øng_sau_d·∫•u,
    "errors": [
        {
            "word": "t·ª´_ho·∫∑c_c·ª•m_k√Ω_t·ª±_g√¢y_l·ªói",
            "line_number": s·ªë_d√≤ng,
            "error_type": "spelling" | "formatting",
            "suggestion": "g·ª£i_√Ω_s·ª≠a_ng·∫Øn_g·ªçn",
            "context": "ng·ªØ_c·∫£nh_b·∫±ng_ti·∫øng_vi·ªát",
            "severity": "low" | "medium" | "high"
        }
    ],
    "overall_score": ƒëi·ªÉm_t·ªïng_quan_0_100,
    "suggestions": ["g·ª£i_√Ω_1", "g·ª£i_√Ω_2"],
    "summary": "t√≥m_t·∫Øt_k·∫øt_qu·∫£_b·∫±ng_ti·∫øng_vi·ªát"
}

V√≠ d·ª• context ti·∫øng Vi·ªát:
- "T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ k·ªπ nƒÉng"
- "T√™n v·ªã tr√≠ c√¥ng vi·ªác c·∫ßn vi·∫øt hoa ƒë√∫ng c√°ch"
- "Thi·∫øu kho·∫£ng tr·∫Øng sau d·∫•u ',' trong c√¢u"
- "C√≥ nhi·ªÅu h∆°n 1 kho·∫£ng tr·∫Øng sau d·∫•u ':'"

Ti√™u ch√≠ ƒë√°nh gi√° ƒëi·ªÉm:
- 90-100: Ho√†n h·∫£o ho·∫∑c ch·ªâ c√≥ 1-2 l·ªói nh·ªè
- 70-89: Kh√° t·ªët, c√≥ m·ªôt s·ªë l·ªói nh·ªè
- 50-69: Trung b√¨nh, c√≥ nhi·ªÅu l·ªói
- 0-49: K√©m, c√≥ nhi·ªÅu l·ªói nghi√™m tr·ªçng
"""
        prompt = prompt_template.replace("<<CV_PREVIEW>>", cv_preview)
        return prompt

    def _parse_llm_spell_check_response(self, llm_response: str, cv_text: str) -> SpellCheckResult:
        """Parse response t·ª´ LLM cho spell checking"""
        try:
            import json
            import re

            # T√¨m JSON trong response
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)

                # Parse errors
                errors = []
                for error_data in data.get('errors', []):
                    error = SpellError(
                        word=error_data.get('word', ''),
                        line_number=error_data.get('line_number', 0),
                        error_type=error_data.get('error_type', 'spelling'),
                        suggestion=error_data.get('suggestion', ''),
                        context=error_data.get('context', ''),
                        severity=error_data.get('severity', 'medium')
                    )
                    errors.append(error)

                return SpellCheckResult(
                    total_errors=data.get('total_errors', 0),
                    spelling_errors=data.get('spelling_errors', 0),
                    formatting_errors=data.get('formatting_errors', 0),
                    errors=errors,
                    overall_score=data.get('overall_score', 100),
                    suggestions=data.get('suggestions', []),
                    summary=data.get('summary', 'Kh√¥ng c√≥ l·ªói ch√≠nh t·∫£')
                )

            # Fallback: parse t·ª´ text response
            return self._extract_from_text_response(llm_response, cv_text)

        except Exception as e:
            logger.error(f"‚ùå Error parsing LLM spell check response: {e}")
            return self._extract_from_text_response(llm_response, cv_text)

    def _extract_from_text_response(self, llm_response: str, cv_text: str) -> SpellCheckResult:
        """Tr√≠ch xu·∫•t th√¥ng tin t·ª´ text response n·∫øu JSON parse th·∫•t b·∫°i"""
        try:
            lines = llm_response.split('\n')
            errors = []
            total_errors = 0

            # T√¨m th√¥ng tin v·ªÅ l·ªói trong text response
            for line in lines:
                line_lower = line.lower()

                if 'l·ªói' in line_lower or 'error' in line_lower:
                    if ':' in line:
                        error_part = line.split(':')[1].strip()
                        if error_part.isdigit():
                            total_errors = int(error_part)

                if 'ƒëi·ªÉm' in line_lower or 'score' in line_lower:
                    if ':' in line:
                        score_part = line.split(':')[1].strip()
                        try:
                            score = float(re.findall(r'\d+', score_part)[0])
                        except:
                            score = 100

            # T·∫°o k·∫øt qu·∫£ fallback v·ªõi context ti·∫øng Vi·ªát
            return SpellCheckResult(
                total_errors=total_errors,
                spelling_errors=total_errors // 2,
                formatting_errors=total_errors // 2,
                errors=errors,
                overall_score=score if 'score' in locals() else 100,
                suggestions=["Ki·ªÉm tra l·∫°i ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng"],
                summary=f"T√¨m th·∫•y {total_errors} l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng trong CV"
            )

        except Exception as e:
            logger.error(f"‚ùå Error extracting from text response: {e}")
            return SpellCheckResult(
                total_errors=0,
                spelling_errors=0,
                formatting_errors=0,
                errors=[],
                overall_score=100,
                suggestions=["Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"],
                summary="Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"
            )

    def _fallback_spell_check(self, cv_text: str) -> SpellCheckResult:
        """Fallback spell checking khi LLM kh√¥ng kh·∫£ d·ª•ng"""
        try:
            lines = cv_text.split('\n')
            errors = []
            spelling_count = 0
            formatting_count = 0

            # Danh s√°ch t·ª´ ƒë√∫ng kh√¥ng ƒë∆∞·ª£c b√°o l·ªói
            correct_terms = {
                "backend", "frontend", "fullstack", "developer", "engineer", "programmer",
                "javascript", "python", "java", "csharp", "react", "angular", "vue",
                "nodejs", "express", "django", "aspnet", "sql", "mongodb", "docker",
                "aws", "azure", "git", "github", "agile", "scrum", "kanban",
                "ai", "llm", "machine learning", "deep learning", "neural network",
                "information technology", "software technology", "computer science"
            }

            # Ki·ªÉm tra c∆° b·∫£n: t√¨m t·ª´ c√≥ th·ªÉ sai ch√≠nh t·∫£
            for i, line in enumerate(lines):
                line_lower = line.lower()
                words = line.split()

                # 1) Ki·ªÉm tra ƒë·ªãnh d·∫°ng: kho·∫£ng tr·∫Øng sau d·∫•u , . ; :
                # Thi·∫øu kho·∫£ng tr·∫Øng (nh∆∞ng c√≥ k√Ω t·ª± ch·ªØ theo sau)
                for match in re.finditer(r'([,.;:])(?=[A-Za-z√Ä-·ªπ0-9])', line):
                    punct = match.group(1)
                    col = match.start() + 1
                    # B·ªè qua c√°c ngo·∫°i l·ªá: s·ªë th·∫≠p ph√¢n v√† ph√¢n t√°ch ngh√¨n
                    before = line[max(0, match.start()-2):match.start()+2]
                    if punct == '.' and re.search(r'\d\.\d', before):
                        pass
                    elif punct == ',' and re.search(r'\d,\d{3}', before):
                        pass
                    else:
                        errors.append(SpellError(
                            word=punct,
                            line_number=i + 1,
                            error_type="formatting",
                            suggestion=f"Th√™m 1 kho·∫£ng tr·∫Øng sau '{punct}'",
                            context=f"Thi·∫øu kho·∫£ng tr·∫Øng sau d·∫•u '{punct}' (d√≤ng {i+1})",
                            severity="low"
                        ))
                        formatting_count += 1

                # Th·ª´a kho·∫£ng tr·∫Øng (>1 kho·∫£ng tr·∫Øng)
                for match in re.finditer(r'([,.;:])\s{2,}(?=\S)', line):
                    punct = match.group(1)
                    errors.append(SpellError(
                        word=punct,
                        line_number=i + 1,
                        error_type="formatting",
                        suggestion=f"Ch·ªâ ƒë·ªÉ 1 kho·∫£ng tr·∫Øng sau '{punct}'",
                        context=f"C√≥ h∆°n 1 kho·∫£ng tr·∫Øng sau d·∫•u '{punct}' (d√≤ng {i+1})",
                        severity="low"
                    ))
                    formatting_count += 1

                # 2) Ki·ªÉm tra ch√≠nh t·∫£ ƒë∆°n gi·∫£n (fallback)
                for word in words:
                    # Lo·∫°i b·ªè d·∫•u c√¢u v√† s·ªë
                    clean_word = re.sub(r'[^\w\s]', '', word)

                    if len(clean_word) > 2:
                        # Ki·ªÉm tra t·ª´ ti·∫øng Vi·ªát c∆° b·∫£n
                        if not any(vn_word in clean_word.lower() for vn_word in self.vietnamese_words):
                            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† t√™n ri√™ng ho·∫∑c t·ª´ ƒë√∫ng kh√¥ng
                            if not self._is_proper_noun(clean_word) and clean_word.lower() not in correct_terms:
                                # Ki·ªÉm tra th√™m: kh√¥ng b√°o l·ªói cho c√°c t·ª´ c√≥ th·ªÉ ƒë√∫ng
                                if not self._is_likely_correct(clean_word, line):
                                    # T·∫°o context ti·∫øng Vi·ªát d·ª±a tr√™n ng·ªØ c·∫£nh
                                    context_vn = self._create_vietnamese_context(line, i + 1)
                                    
                                    # C√≥ th·ªÉ l√† l·ªói ch√≠nh t·∫£
                                    error = SpellError(
                                        word=word,
                                        line_number=i + 1,
                                        error_type="spelling",
                                        suggestion=f"Ki·ªÉm tra l·∫°i t·ª´ '{word}'",
                                        context=context_vn,
                                        severity="low"
                                    )
                                    errors.append(error)
                                    spelling_count += 1

            # T√≠nh ƒëi·ªÉm d·ª±a tr√™n s·ªë l·ªói
            total_errors = spelling_count + formatting_count
            if total_errors == 0:
                overall_score = 100
            elif total_errors <= 2:
                overall_score = 95
            elif total_errors <= 5:
                overall_score = 85
            elif total_errors <= 10:
                overall_score = 75
            else:
                overall_score = 65

            return SpellCheckResult(
                total_errors=total_errors,
                spelling_errors=spelling_count,
                formatting_errors=formatting_count,
                errors=errors,
                overall_score=overall_score,
                suggestions=["S·ª≠ d·ª•ng LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£ ch√≠nh x√°c h∆°n"],
                summary=f"Fallback check: T√¨m th·∫•y {total_errors} l·ªói ch√≠nh t·∫£/ƒë·ªãnh d·∫°ng (spelling={spelling_count}, formatting={formatting_count})"
            )

        except Exception as e:
            logger.error(f"‚ùå Error in fallback spell checking: {e}")
            return SpellCheckResult(
                total_errors=0,
                spelling_errors=0,
                formatting_errors=0,
                errors=[],
                overall_score=100,
                suggestions=["Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"],
                summary="Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"
            )

    def _is_proper_noun(self, word: str) -> bool:
        """Ki·ªÉm tra xem t·ª´ c√≥ ph·∫£i l√† danh t·ª´ ri√™ng kh√¥ng"""
        # Danh t·ª´ ri√™ng th∆∞·ªùng vi·∫øt hoa
        if word[0].isupper() and len(word) > 2:
            return True

        # T√™n c√¥ng ty, c√¥ng ngh·ªá ph·ªï bi·∫øn
        tech_terms = {
            "microsoft", "google", "facebook", "amazon", "apple", "netflix",
            "react", "angular", "vue", "node", "python", "java", "javascript",
            "html", "css", "sql", "mongodb", "docker", "kubernetes", "aws",
            "azure", "github", "gitlab", "bitbucket", "jira", "confluence"
        }

        if word.lower() in tech_terms:
            return True

        return False

    def _is_likely_correct(self, word: str, context: str) -> bool:
        """Ki·ªÉm tra xem t·ª´ c√≥ kh·∫£ nƒÉng ƒë√∫ng kh√¥ng d·ª±a tr√™n ng·ªØ c·∫£nh"""
        word_lower = word.lower()
        context_lower = context.lower()
        
        # C√°c pattern cho t·ª´ c√≥ th·ªÉ ƒë√∫ng
        patterns = [
            r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b',  # Proper nouns like "Backend Developer"
            r'\b[A-Z]{2,}\b',  # Acronyms like "AI", "LLM", "API"
            r'\b[A-Za-z]+\.NET\b',  # .NET technologies
            r'\b[A-Za-z]+\.js\b',  # JavaScript frameworks
            r'\b[A-Za-z]+\.py\b',  # Python frameworks
        ]
        
        for pattern in patterns:
            if re.match(pattern, word):
                return True
        
        # Ki·ªÉm tra ng·ªØ c·∫£nh
        if any(tech in context_lower for tech in ['technology', 'framework', 'library', 'tool']):
            return True
            
        if any(company in context_lower for company in ['company', 'corporation', 'inc', 'ltd']):
            return True
            
        return False

    def _create_vietnamese_context(self, line: str, line_number: int) -> str:
        """T·∫°o context ti·∫øng Vi·ªát cho l·ªói ch√≠nh t·∫£"""
        line_lower = line.lower()
        
        # X√°c ƒë·ªãnh lo·∫°i n·ªôi dung d·ª±a tr√™n t·ª´ kh√≥a
        if any(word in line_lower for word in ['k·ªπ nƒÉng', 'skill', 'technology', 'framework']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ k·ªπ nƒÉng (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['v·ªã tr√≠', 'position', 'job', 'title']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ v·ªã tr√≠ c√¥ng vi·ªác (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['d·ª± √°n', 'project', 'description']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn m√¥ t·∫£ d·ª± √°n (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['c√¥ng ty', 'company', 'organization']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn th√¥ng tin c√¥ng ty (d√≤ng {line_number})"
        elif any(word in line_lower for word in ['h·ªçc v·∫•n', 'education', 'degree', 'school']):
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong ph·∫ßn th√¥ng tin h·ªçc v·∫•n (d√≤ng {line_number})"
        else:
            return f"T·ª´ n√†y xu·∫•t hi·ªán trong n·ªôi dung CV (d√≤ng {line_number})"
