import logging
import openai
import os
import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class SpellError:
    """Th√¥ng tin v·ªÅ l·ªói ch√≠nh t·∫£/ƒë·ªãnh d·∫°ng"""
    word: str
    line_number: int
    error_type: str  # "spelling" ho·∫∑c "formatting"
    suggestion: str
    context: str
    severity: str  # "low", "medium", "high"

@dataclass
class SpellCheckResult:
    """K·∫øt qu·∫£ ki·ªÉm tra ch√≠nh t·∫£"""
    total_errors: int
    spelling_errors: int
    formatting_errors: int
    errors: List[SpellError]
    overall_score: float  # 0-100
    suggestions: List[str]
    summary: str

class CVSpellChecker:
    """Ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng cho CV s·ª≠ d·ª•ng LLM"""

    def __init__(self):
        self.client = None
        self._init_openai_client()

        # T·ª´ ƒëi·ªÉn ti·∫øng Vi·ªát c∆° b·∫£n ƒë·ªÉ fallback
        self.vietnamese_words = {
            "nguy·ªÖn", "tr·∫ßn", "l√™", "ph·∫°m", "ho√†ng", "hu·ª≥nh", "phan", "v≈©", "v√µ",
            "ƒë·∫∑ng", "b√πi", "ƒë·ªó", "h·ªì", "ng√¥", "d∆∞∆°ng", "l√Ω", "ƒëinh", "t√¥", "l√¢m",
            "tr·ªãnh", "ƒëo√†n", "ph√πng", "ki·ªÅu", "cao", "t·∫°", "h√†", "tƒÉng", "l∆∞u",
            "t·ªëng", "ch√¢u", "t·ª´", "h·ª©a", "h·ªìng", "minh", "th√†nh", "c√¥ng", "thi·ªán",
            "th·ªã", "vƒÉn", "ƒë·ª©c", "quang", "huy", "tu·∫•n", "d≈©ng", "h√πng", "nam",
            "developer", "engineer", "programmer", "analyst", "manager", "specialist",
            "javascript", "python", "java", "csharp", "react", "angular", "vue",
            "nodejs", "express", "django", "aspnet", "sql", "mongodb", "docker",
            "aws", "azure", "git", "github", "agile", "scrum", "kanban"
        }

    def _init_openai_client(self):
        """Kh·ªüi t·∫°o OpenAI client"""
        try:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.client = openai.OpenAI(api_key=api_key)
                logger.info("‚úÖ OpenAI client initialized for spell checking")
            else:
                logger.warning("‚ö†Ô∏è OPENAI_API_KEY not found for spell checking")
        except Exception as e:
            logger.error(f"‚ùå Error initializing OpenAI client for spell checking: {e}")

    def check_cv_spelling(self, cv_text: str) -> SpellCheckResult:
        """Ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng cho CV"""
        try:
            if not self.client:
                logger.warning("‚ö†Ô∏è OpenAI client not available, using fallback spell checking")
                return self._fallback_spell_check(cv_text)

            # T·∫°o prompt cho LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£
            prompt = self._create_spell_check_prompt(cv_text)

            # G·ªçi OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "B·∫°n l√† m·ªôt chuy√™n gia ki·ªÉm tra ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng ti·∫øng Vi·ªát v√† ti·∫øng Anh. H√£y ki·ªÉm tra CV v√† t√¨m ra c√°c l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng. Tr·∫£ v·ªÅ k·∫øt qu·∫£ theo format JSON."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=1000
            )

            # X·ª≠ l√Ω response t·ª´ LLM
            llm_response = response.choices[0].message.content
            logger.info(f"ü§ñ LLM Spell Check Response: {llm_response}")

            # Parse k·∫øt qu·∫£ t·ª´ LLM
            spell_check_result = self._parse_llm_spell_check_response(llm_response, cv_text)

            if spell_check_result.total_errors > 0:
                logger.info(f"‚úÖ LLM found {spell_check_result.total_errors} errors in CV")
            else:
                logger.info("‚úÖ LLM found no errors in CV")

            return spell_check_result

        except Exception as e:
            logger.error(f"‚ùå Error in LLM spell checking: {e}")
            return self._fallback_spell_check(cv_text)

    def _create_spell_check_prompt(self, cv_text: str) -> str:
        """T·∫°o prompt cho LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£"""
        # L·∫•y 30 d√≤ng ƒë·∫ßu ƒë·ªÉ gi·∫£m token usage
        lines = cv_text.split('\n')
        cv_preview = '\n'.join(lines[:30])

        prompt = f"""
H√£y ki·ªÉm tra ch√≠nh t·∫£ t·ª´ ng·ªØ v√† ƒë·ªãnh d·∫°ng c·ªßa CV sau ƒë√¢y:

CV TEXT:
{cv_preview}

Y√™u c·∫ßu ki·ªÉm tra:
1. L·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát v√† ti·∫øng Anh (spelling)
2. L·ªói ƒë·ªãnh d·∫°ng (formatting) - vi·∫øt hoa, kho·∫£ng tr·∫Øng, cƒÉn l·ªÅ
3. ƒê·ªÅ xu·∫•t c√°ch s·ª≠a l·ªói

H√£y tr·∫£ v·ªÅ k·∫øt qu·∫£ theo format JSON:
{{
    "total_errors": s·ªë_l·ªói_t·ªïng,
    "spelling_errors": s·ªë_l·ªói_ch√≠nh_t·∫£,
    "formatting_errors": s·ªë_l·ªói_ƒë·ªãnh_d·∫°ng,
    "errors": [
        {{
            "word": "t·ª´_sai",
            "line_number": s·ªë_d√≤ng,
            "error_type": "spelling_ho·∫∑c_formatting",
            "suggestion": "g·ª£i_√Ω_s·ª≠a",
            "context": "ng·ªØ_c·∫£nh",
            "severity": "m·ª©c_ƒë·ªô_nghi√™m_tr·ªçng"
        }}
    ],
    "overall_score": ƒëi·ªÉm_t·ªïng_quan_0_100,
    "suggestions": ["g·ª£i_√Ω_1", "g·ª£i_√Ω_2"],
    "summary": "t√≥m_t·∫Øt_k·∫øt_qu·∫£"
}}

L∆∞u √Ω:
- Ch·ªâ ki·ªÉm tra l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng
- ƒêi·ªÉm 0-100: 90-100 (t·ªët), 70-89 (kh√°), 50-69 (trung b√¨nh), 0-49 (k√©m)
- Severity: "low" (nh·∫π), "medium" (trung b√¨nh), "high" (nghi√™m tr·ªçng)
- Error types: ch·ªâ "spelling" v√† "formatting"
"""
        return prompt

    def _parse_llm_spell_check_response(self, llm_response: str, cv_text: str) -> SpellCheckResult:
        """Parse response t·ª´ LLM cho spell checking"""
        try:
            import json
            import re

            # T√¨m JSON trong response
            json_match = re.search(r'\{.*\}', llm_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)

                # Parse errors
                errors = []
                for error_data in data.get('errors', []):
                    error = SpellError(
                        word=error_data.get('word', ''),
                        line_number=error_data.get('line_number', 0),
                        error_type=error_data.get('error_type', 'spelling'),
                        suggestion=error_data.get('suggestion', ''),
                        context=error_data.get('context', ''),
                        severity=error_data.get('severity', 'medium')
                    )
                    errors.append(error)

                return SpellCheckResult(
                    total_errors=data.get('total_errors', 0),
                    spelling_errors=data.get('spelling_errors', 0),
                    formatting_errors=data.get('formatting_errors', 0),
                    errors=errors,
                    overall_score=data.get('overall_score', 100),
                    suggestions=data.get('suggestions', []),
                    summary=data.get('summary', 'Kh√¥ng c√≥ l·ªói ch√≠nh t·∫£')
                )

            # Fallback: parse t·ª´ text response
            return self._extract_from_text_response(llm_response, cv_text)

        except Exception as e:
            logger.error(f"‚ùå Error parsing LLM spell check response: {e}")
            return self._extract_from_text_response(llm_response, cv_text)

    def _extract_from_text_response(self, llm_response: str, cv_text: str) -> SpellCheckResult:
        """Tr√≠ch xu·∫•t th√¥ng tin t·ª´ text response n·∫øu JSON parse th·∫•t b·∫°i"""
        try:
            lines = llm_response.split('\n')
            errors = []
            total_errors = 0

            # T√¨m th√¥ng tin v·ªÅ l·ªói trong text response
            for line in lines:
                line_lower = line.lower()

                if 'l·ªói' in line_lower or 'error' in line_lower:
                    if ':' in line:
                        error_part = line.split(':')[1].strip()
                        if error_part.isdigit():
                            total_errors = int(error_part)

                if 'ƒëi·ªÉm' in line_lower or 'score' in line_lower:
                    if ':' in line:
                        score_part = line.split(':')[1].strip()
                        try:
                            score = float(re.findall(r'\d+', score_part)[0])
                        except:
                            score = 100

            # T·∫°o k·∫øt qu·∫£ fallback
            return SpellCheckResult(
                total_errors=total_errors,
                spelling_errors=total_errors // 2,
                formatting_errors=total_errors // 2,
                errors=errors,
                overall_score=score if 'score' in locals() else 100,
                suggestions=["Ki·ªÉm tra l·∫°i ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng"],
                summary=f"T√¨m th·∫•y {total_errors} l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng"
            )

        except Exception as e:
            logger.error(f"‚ùå Error extracting from text response: {e}")
            return SpellCheckResult(
                total_errors=0,
                spelling_errors=0,
                formatting_errors=0,
                errors=[],
                overall_score=100,
                suggestions=["Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"],
                summary="Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"
            )

    def _fallback_spell_check(self, cv_text: str) -> SpellCheckResult:
        """Fallback spell checking khi LLM kh√¥ng kh·∫£ d·ª•ng"""
        try:
            lines = cv_text.split('\n')
            errors = []
            total_errors = 0

            # Ki·ªÉm tra c∆° b·∫£n: t√¨m t·ª´ c√≥ th·ªÉ sai ch√≠nh t·∫£
            for i, line in enumerate(lines):
                line_lower = line.lower()
                words = line.split()

                for word in words:
                    # Lo·∫°i b·ªè d·∫•u c√¢u v√† s·ªë
                    clean_word = re.sub(r'[^\w\s]', '', word)

                    if len(clean_word) > 2:
                        # Ki·ªÉm tra t·ª´ ti·∫øng Vi·ªát c∆° b·∫£n
                        if not any(vn_word in clean_word.lower() for vn_word in self.vietnamese_words):
                            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† t√™n ri√™ng kh√¥ng
                            if not self._is_proper_noun(clean_word):
                                # C√≥ th·ªÉ l√† l·ªói ch√≠nh t·∫£
                                error = SpellError(
                                    word=word,
                                    line_number=i + 1,
                                    error_type="spelling",
                                    suggestion=f"Ki·ªÉm tra l·∫°i t·ª´ '{word}'",
                                    context=line.strip(),
                                    severity="low"
                                )
                                errors.append(error)
                                total_errors += 1

            # T√≠nh ƒëi·ªÉm d·ª±a tr√™n s·ªë l·ªói
            if total_errors == 0:
                overall_score = 100
            elif total_errors <= 3:
                overall_score = 90
            elif total_errors <= 7:
                overall_score = 80
            elif total_errors <= 15:
                overall_score = 70
            else:
                overall_score = 60

            return SpellCheckResult(
                total_errors=total_errors,
                spelling_errors=total_errors // 2,
                formatting_errors=total_errors // 2,
                errors=errors,
                overall_score=overall_score,
                suggestions=["S·ª≠ d·ª•ng LLM ƒë·ªÉ ki·ªÉm tra ch√≠nh t·∫£ ch√≠nh x√°c h∆°n"],
                summary=f"Fallback check: T√¨m th·∫•y {total_errors} l·ªói ch√≠nh t·∫£ v√† ƒë·ªãnh d·∫°ng"
            )

        except Exception as e:
            logger.error(f"‚ùå Error in fallback spell checking: {e}")
            return SpellCheckResult(
                total_errors=0,
                spelling_errors=0,
                formatting_errors=0,
                errors=[],
                overall_score=100,
                suggestions=["Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"],
                summary="Kh√¥ng th·ªÉ ki·ªÉm tra ch√≠nh t·∫£"
            )

    def _is_proper_noun(self, word: str) -> bool:
        """Ki·ªÉm tra xem t·ª´ c√≥ ph·∫£i l√† danh t·ª´ ri√™ng kh√¥ng"""
        # Danh t·ª´ ri√™ng th∆∞·ªùng vi·∫øt hoa
        if word[0].isupper() and len(word) > 2:
            return True

        # T√™n c√¥ng ty, c√¥ng ngh·ªá ph·ªï bi·∫øn
        tech_terms = {
            "microsoft", "google", "facebook", "amazon", "apple", "netflix",
            "react", "angular", "vue", "node", "python", "java", "javascript",
            "html", "css", "sql", "mongodb", "docker", "kubernetes", "aws",
            "azure", "github", "gitlab", "bitbucket", "jira", "confluence"
        }

        if word.lower() in tech_terms:
            return True

        return False
