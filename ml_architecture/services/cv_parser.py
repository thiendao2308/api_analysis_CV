import re
import spacy
from typing import Dict, List, Optional, Tuple
import PyPDF2
import fitz  # PyMuPDF
from docx import Document
import logging

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class IntelligentCVParser:
    def __init__(self):
        """Kh·ªüi t·∫°o parser v·ªõi c√°c pattern v√† rules th√¥ng minh"""
        self.nlp = spacy.load("en_core_web_sm")
        
        # Patterns ƒë·ªÉ nh·∫≠n di·ªán job title
        self.job_title_patterns = [
            r"(?i)(frontend|front-end|front end)\s+(developer|dev)",
            r"(?i)(backend|back-end|back end)\s+(developer|dev)",
            r"(?i)(fullstack|full-stack|full stack)\s+(developer|dev)",
            r"(?i)(mobile|android|ios)\s+(developer|dev)",
            r"(?i)(data\s+scientist|data\s+analyst)",
            r"(?i)(devops|cloud)\s+(engineer|dev)",
            r"(?i)(qa|quality|test)\s+(engineer|analyst)",
            r"(?i)(ui|ux|user\s+interface)\s+(designer|developer)",
            r"(?i)(system|network)\s+(admin|administrator)",
            r"(?i)(cyber|security)\s+(specialist|engineer)",
            r"(?i)(marketing|digital\s+marketing|seo)\s+(specialist|manager)",
            r"(?i)(sales|business)\s+(representative|manager|director)",
            r"(?i)(hr|human\s+resources)\s+(specialist|manager)",
            r"(?i)(accountant|auditor|financial)\s+(specialist|manager)",
            r"(?i)(teacher|professor|educator)",
            r"(?i)(doctor|nurse|pharmacist|medical)",
            r"(?i)(lawyer|legal|attorney)",
            r"(?i)(consultant|advisor)",
            r"(?i)(designer|graphic|web|product)\s+(designer)",
        ]
        
        # Keywords ƒë·ªÉ nh·∫≠n di·ªán sections
        self.section_keywords = {
            "experience": [
                "experience", "work experience", "employment", "career", "professional",
                "kinh nghi·ªám", "kinh nghi·ªám l√†m vi·ªác", "ngh·ªÅ nghi·ªáp", "c√¥ng vi·ªác"
            ],
            "education": [
                "education", "academic", "degree", "university", "college", "school",
                "h·ªçc v·∫•n", "b·∫±ng c·∫•p", "ƒë·∫°i h·ªçc", "tr∆∞·ªùng h·ªçc", "t·ªët nghi·ªáp"
            ],
            "skills": [
                "skills", "technical skills", "competencies", "abilities", "proficiencies",
                "k·ªπ nƒÉng", "k·ªπ nƒÉng k·ªπ thu·∫≠t", "nƒÉng l·ª±c", "kh·∫£ nƒÉng"
            ],
            "projects": [
                "projects", "portfolio", "achievements", "accomplishments",
                "d·ª± √°n", "danh m·ª•c", "th√†nh t·ª±u", "k·∫øt qu·∫£"
            ],
            "certifications": [
                "certifications", "certificates", "licenses", "accreditations",
                "ch·ª©ng ch·ªâ", "gi·∫•y ph√©p", "ch·ª©ng nh·∫≠n"
            ]
        }
        
        # Skills mapping theo ng√†nh ngh·ªÅ
        self.skills_by_category = {
            "INFORMATION-TECHNOLOGY": [
                "python", "java", "javascript", "react", "angular", "vue", "node.js",
                "django", "flask", "spring", "sql", "mongodb", "postgresql", "mysql",
                "aws", "azure", "docker", "kubernetes", "git", "jenkins", "jira",
                "html", "css", "sass", "typescript", "php", "c#", ".net", "ruby",
                "go", "rust", "swift", "kotlin", "android", "ios", "flutter",
                "machine learning", "ai", "data science", "big data", "hadoop",
                "spark", "tensorflow", "pytorch", "scikit-learn", "pandas", "numpy"
            ],
            "MARKETING": [
                "digital marketing", "seo", "sem", "google ads", "facebook ads",
                "social media", "content marketing", "email marketing", "analytics",
                "google analytics", "facebook pixel", "conversion optimization",
                "brand management", "market research", "customer acquisition",
                "lead generation", "sales funnel", "crm", "hubspot", "mailchimp"
            ],
            "FINANCE": [
                "financial analysis", "accounting", "bookkeeping", "auditing",
                "tax preparation", "budgeting", "forecasting", "investment",
                "risk management", "compliance", "quickbooks", "excel", "sap",
                "oracle", "financial modeling", "valuation", "mergers", "acquisitions"
            ],
            "SALES": [
                "sales", "business development", "account management", "lead generation",
                "prospecting", "negotiation", "closing", "crm", "salesforce",
                "pipeline management", "territory management", "customer relationship",
                "presentation", "communication", "cold calling", "sales strategy"
            ],
            "HR": [
                "recruitment", "talent acquisition", "hiring", "interviewing",
                "onboarding", "employee relations", "performance management",
                "compensation", "benefits", "training", "development", "hr policies",
                "workday", "bamboo hr", "adp", "payroll", "compliance", "diversity"
            ]
        }

    def extract_text_from_file(self, file_path: str) -> str:
        """Tr√≠ch xu·∫•t text t·ª´ file CV (PDF, DOCX, TXT)"""
        try:
            if file_path.lower().endswith('.pdf'):
                return self._extract_from_pdf(file_path)
            elif file_path.lower().endswith('.docx'):
                return self._extract_from_docx(file_path)
            elif file_path.lower().endswith('.txt'):
                return self._extract_from_txt(file_path)
            else:
                raise ValueError(f"Unsupported file format: {file_path}")
        except Exception as e:
            logger.error(f"Error extracting text from {file_path}: {str(e)}")
            return ""

    def _extract_from_pdf(self, file_path: str) -> str:
        """Tr√≠ch xu·∫•t text t·ª´ PDF v·ªõi fallback methods"""
        text = ""
        
        # Th·ª≠ PyMuPDF tr∆∞·ªõc (t·ªët h∆°n cho layout ph·ª©c t·∫°p)
        try:
            doc = fitz.open(file_path)
            for page in doc:
                text += page.get_text()
            doc.close()
            if text.strip():
                return text
        except Exception as e:
            logger.warning(f"PyMuPDF failed: {e}")
        
        # Fallback to PyPDF2
        try:
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                for page in reader.pages:
                    text += page.extract_text() + "\n"
            return text
        except Exception as e:
            logger.error(f"PyPDF2 failed: {e}")
            return ""

    def _extract_from_docx(self, file_path: str) -> str:
        """Tr√≠ch xu·∫•t text t·ª´ DOCX"""
        try:
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"
            return text
        except Exception as e:
            logger.error(f"Error extracting from DOCX: {e}")
            return ""

    def _extract_from_txt(self, file_path: str) -> str:
        """Tr√≠ch xu·∫•t text t·ª´ TXT"""
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return file.read()
        except Exception as e:
            logger.error(f"Error extracting from TXT: {e}")
            return ""

    def extract_job_title(self, text: str) -> Optional[str]:
        """Tr√≠ch xu·∫•t job title th√¥ng minh t·ª´ CV s·ª≠ d·ª•ng LLM"""
        try:
            # Th·ª≠ d√πng LLM tr∆∞·ªõc
            job_title = self._extract_job_title_with_llm(text)
            if job_title:
                return job_title
            
            # Fallback v·ªÅ rules c≈© n·∫øu LLM th·∫•t b·∫°i
            return self._extract_job_title_with_rules(text)
            
        except Exception as e:
            logger.error(f"Error extracting job title: {e}")
            return self._extract_job_title_with_rules(text)

    def _extract_job_title_with_llm(self, text: str) -> Optional[str]:
        """Tr√≠ch xu·∫•t job title b·∫±ng LLM"""
        try:
            # L·∫•y 15 d√≤ng ƒë·∫ßu ƒë·ªÉ gi·∫£m token usage
            lines = text.split('\n')
            cv_preview = '\n'.join(lines[:15])
            
            prompt = f"""
            H√£y tr√≠ch xu·∫•t job title/v·ªã tr√≠ c√¥ng vi·ªác ch√≠nh t·ª´ CV sau ƒë√¢y.
            
            CV TEXT:
            {cv_preview}
            
            Y√™u c·∫ßu:
            1. T√¨m v·ªã tr√≠ c√¥ng vi·ªác ch√≠nh (Frontend Developer, Backend Developer, Full Stack Developer, etc.)
            2. N·∫øu c√≥ nhi·ªÅu v·ªã tr√≠, ch·ªçn v·ªã tr√≠ g·∫ßn nh·∫•t ho·∫∑c ch√≠nh
            3. Tr·∫£ v·ªÅ ch·ªâ t√™n v·ªã tr√≠, kh√¥ng c√≥ gi·∫£i th√≠ch
            
            Tr·∫£ v·ªÅ: "Job Title" ho·∫∑c null n·∫øu kh√¥ng t√¨m th·∫•y
            """
            
            # G·ªçi OpenAI API
            import openai
            import os
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                return None
                
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50,
                temperature=0.1,
            )
            
            job_title = response.choices[0].message.content.strip()
            
            # Clean up response
            if job_title and job_title.lower() != "null" and len(job_title) < 100:
                return job_title
                
            return None
            
        except Exception as e:
            logger.error(f"LLM job title extraction failed: {e}")
            return None

    def _extract_job_title_with_rules(self, text: str) -> Optional[str]:
        """Fallback: tr√≠ch xu·∫•t job title b·∫±ng rules c≈©"""
        lines = text.split('\n')
        
        # T√¨m trong 10 d√≤ng ƒë·∫ßu (th∆∞·ªùng job title ·ªü ƒë·∫ßu CV)
        for i, line in enumerate(lines[:10]):
            line = line.strip()
            
            # B·ªè qua d√≤ng tr·ªëng ho·∫∑c qu√° ng·∫Øn
            if len(line) < 3 or len(line) > 100:
                continue
                
            # Ki·ªÉm tra c√°c t·ª´ kh√≥a job title ƒë∆°n gi·∫£n
            job_keywords = [
                "developer", "engineer", "manager", "specialist", "analyst",
                "designer", "consultant", "advisor", "coordinator", "assistant",
                "director", "supervisor", "lead", "senior", "junior"
            ]
            
            line_lower = line.lower()
            if any(keyword in line_lower for keyword in job_keywords):
                return line.strip()
        
        return None

    def extract_sections(self, text: str) -> Dict[str, str]:
        """Tr√≠ch xu·∫•t c√°c section t·ª´ CV"""
        sections = {}
        lines = text.split('\n')
        current_section = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # Ki·ªÉm tra xem line c√≥ ph·∫£i l√† section header kh√¥ng
            section_found = False
            for section_name, keywords in self.section_keywords.items():
                for keyword in keywords:
                    if keyword.lower() in line.lower():
                        # L∆∞u section tr∆∞·ªõc ƒë√≥
                        if current_section and current_content:
                            sections[current_section] = '\n'.join(current_content)
                        
                        # B·∫Øt ƒë·∫ßu section m·ªõi
                        current_section = section_name
                        current_content = [line]
                        section_found = True
                        break
                if section_found:
                    break
            
            # N·∫øu kh√¥ng ph·∫£i header, th√™m v√†o content hi·ªán t·∫°i
            if not section_found and current_section:
                current_content.append(line)
        
        # L∆∞u section cu·ªëi c√πng
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content)
        
        return sections

    def extract_skills(self, text: str, job_category: str = None) -> List[str]:
        """Tr√≠ch xu·∫•t skills t·ª´ CV"""
        skills = []
        
        # T√¨m trong section skills
        sections = self.extract_sections(text)
        skills_section = sections.get('skills', '')
        
        # T√°ch skills t·ª´ skills section
        if skills_section:
            # T√°ch theo d·∫•u ph·∫©y, ch·∫•m ph·∫©y, g·∫°ch ƒë·∫ßu d√≤ng
            skill_patterns = [
                r'[‚Ä¢\-\*]\s*([^,\n]+)',
                r'([^,\n]+)(?=,|;|\n)',
                r'([^,\n]+)'
            ]
            
            for pattern in skill_patterns:
                matches = re.findall(pattern, skills_section, re.IGNORECASE)
                for match in matches:
                    skill = match.strip()
                    if len(skill) > 2 and skill.lower() not in ['and', 'or', 'the', 'with']:
                        skills.append(skill)
        
        # T√¨m skills trong to√†n b·ªô text
        if job_category and job_category in self.skills_by_category:
            category_skills = self.skills_by_category[job_category]
            for skill in category_skills:
                if re.search(rf'\b{re.escape(skill)}\b', text, re.IGNORECASE):
                    if skill not in skills:
                        skills.append(skill)
        
        return list(set(skills))  # Lo·∫°i b·ªè duplicates

    def extract_summary(self, text: str) -> Optional[str]:
        """Tr√≠ch xu·∫•t summary/objective t·ª´ CV - c·∫£i thi·ªán ƒë·ªÉ t·ª± ph√°t hi·ªán t·ªët h∆°n"""
        try:
            # T√¨m summary trong 30 d√≤ng ƒë·∫ßu (tƒÉng t·ª´ 20)
            lines = text.split('\n')
            summary_lines = []
            
            # B∆Ø·ªöC 1: T√¨m theo t·ª´ kh√≥a section header
            for i, line in enumerate(lines[:30]):
                line = line.strip()
                if not line:
                    continue
                    
                # T√¨m c√°c t·ª´ kh√≥a summary
                summary_keywords = [
                    'summary', 'objective', 'profile', 'about', 'introduction',
                    't√≥m t·∫Øt', 'm·ª•c ti√™u', 'gi·ªõi thi·ªáu', 'profile', 'overview'
                ]
                
                line_lower = line.lower()
                if any(keyword in line_lower for keyword in summary_keywords):
                    # L·∫•y 2-4 d√≤ng ti·∫øp theo l√†m summary
                    for j in range(i+1, min(i+5, len(lines))):
                        next_line = lines[j].strip()
                        if next_line and len(next_line) > 10 and len(next_line) < 300:
                            summary_lines.append(next_line)
                        else:
                            break
                    break
            
            # B∆Ø·ªöC 2: N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c theo keyword, t·ª± ph√°t hi·ªán summary
            if not summary_lines:
                summary_lines = self._auto_detect_summary(lines)
            
            # B∆Ø·ªöC 3: N·∫øu v·∫´n kh√¥ng c√≥, t·∫°o summary t·ª´ job title v√† skills
            if not summary_lines:
                summary_lines = self._generate_summary_from_context(text)
            
            if summary_lines:
                return ' '.join(summary_lines)
            return None
            
        except Exception as e:
            logger.error(f"Error extracting summary: {e}")
            return None

    def _auto_detect_summary(self, lines: List[str]) -> List[str]:
        """T·ª± ƒë·ªông ph√°t hi·ªán summary d·ª±a tr√™n pattern v√† n·ªôi dung - c·∫£i thi·ªán"""
        summary_lines = []
        
        # T√¨m trong 15 d√≤ng ƒë·∫ßu (tƒÉng t·ª´ 10)
        for i, line in enumerate(lines[:15]):
            line = line.strip()
            if not line:
                continue
            
            # B·ªè qua d√≤ng qu√° ng·∫Øn ho·∫∑c qu√° d√†i
            if len(line) < 15 or len(line) > 300:
                continue
            
            # B·ªè qua d√≤ng c√≥ v·∫ª l√† header (to√†n ch·ªØ hoa, c√≥ d·∫•u g·∫°ch d∆∞·ªõi)
            if line.isupper() or '_' in line or line.count('-') > 2:
                continue
            
            # B·ªè qua d√≤ng c√≥ v·∫ª l√† contact info (email, phone, address)
            if '@' in line or re.search(r'\d{10,}', line) or 'street' in line.lower():
                continue
            
            # B·ªè qua d√≤ng c√≥ v·∫ª l√† job title (qu√° ng·∫Øn, c√≥ t·ª´ kh√≥a job)
            job_keywords = ['developer', 'engineer', 'manager', 'specialist', 'analyst']
            if len(line) < 30 and any(keyword in line.lower() for keyword in job_keywords):
                continue
            
            # B·ªè qua d√≤ng c√≥ v·∫ª l√† section header
            section_keywords = ['experience', 'education', 'skills', 'projects', 'kinh nghi·ªám', 'h·ªçc v·∫•n', 'k·ªπ nƒÉng', 'd·ª± √°n']
            if any(keyword in line.lower() for keyword in section_keywords):
                continue
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i l√† c√¢u m√¥ t·∫£ kh√¥ng
            if self._is_descriptive_sentence(line):
                summary_lines.append(line)
                if len(summary_lines) >= 3:  # L·∫•y t·ªëi ƒëa 3 d√≤ng
                    break
        
        return summary_lines

    def _is_descriptive_sentence(self, text: str) -> bool:
        """Ki·ªÉm tra xem text c√≥ ph·∫£i l√† c√¢u m√¥ t·∫£ kh√¥ng - c·∫£i thi·ªán"""
        # B·ªè qua d√≤ng qu√° ng·∫Øn
        if len(text) < 20:
            return False
        
        # B·ªè qua d√≤ng ch·ªâ c√≥ danh s√°ch
        if text.count(',') > 3 or text.count('‚Ä¢') > 2:
            return False
        
        # B·ªè qua d√≤ng c√≥ v·∫ª l√† bullet point
        if text.startswith('‚Ä¢') or text.startswith('-') or text.startswith('*'):
            return False
        
        # B·ªè qua d√≤ng c√≥ v·∫ª l√† contact info
        if re.search(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text):
            return False
        
        # Ki·ªÉm tra c√≥ v·∫ª l√† c√¢u m√¥ t·∫£ (c√≥ ƒë·ªông t·ª´, t√≠nh t·ª´)
        descriptive_words = [
            'experience', 'skilled', 'proficient', 'expertise', 'background',
            'passionate', 'dedicated', 'motivated', 'creative', 'analytical',
            'kinh nghi·ªám', 'th√†nh th·∫°o', 'chuy√™n m√¥n', 'ƒëam m√™', 's√°ng t·∫°o',
            'developed', 'created', 'built', 'implemented', 'designed',
            'ph√°t tri·ªÉn', 't·∫°o ra', 'x√¢y d·ª±ng', 'thi·∫øt k·∫ø', 'th·ª±c hi·ªán'
        ]
        
        text_lower = text.lower()
        if any(word in text_lower for word in descriptive_words):
            return True
        
        # Ki·ªÉm tra c√≥ v·∫ª l√† c√¢u ho√†n ch·ªânh (c√≥ d·∫•u ch·∫•m, d·∫•u ph·∫©y)
        if '.' in text or ',' in text:
            return True
        
        # Ki·ªÉm tra c√≥ v·∫ª l√† c√¢u m√¥ t·∫£ v·ªÅ b·∫£n th√¢n
        personal_words = ['i am', 'i\'m', 'i have', 'my', 't√¥i l√†', 't√¥i c√≥', 'c·ªßa t√¥i']
        if any(word in text_lower for word in personal_words):
            return True
        
        return False

    def _generate_summary_from_context(self, text: str) -> List[str]:
        """T·∫°o summary t·ª´ context c·ªßa CV (job title, skills, education)"""
        try:
            # L·∫•y job title
            job_title = self.extract_job_title(text)
            if not job_title:
                job_title = "Software Developer"
            
            # L·∫•y skills ch√≠nh
            skills = self.extract_skills(text)
            main_skills = skills[:5] if skills else ["Programming", "Problem Solving"]
            
            # L·∫•y education
            education = self.extract_education(text)
            degree = "Information Technology" if not education else str(education[0].get('degree', 'Information Technology'))
            
            # T·∫°o summary t·ª± ƒë·ªông
            summary = f"{job_title} v·ªõi ki·∫øn th·ª©c v·ªÅ {', '.join(main_skills[:3])}. T·ªët nghi·ªáp {degree} v√† c√≥ kh·∫£ nƒÉng h·ªçc h·ªèi nhanh."
            
            return [summary]
            
        except Exception as e:
            logger.error(f"Error generating summary from context: {e}")
            return []

    def extract_experience(self, text: str) -> List[Dict]:
        """Tr√≠ch xu·∫•t kinh nghi·ªám l√†m vi·ªác - c·∫£i thi·ªán ƒë·ªÉ nh·∫≠n di·ªán c·∫•u tr√∫c th·ª±c t·∫ø"""
        experience = []
        
        try:
            # B∆Ø·ªöC 1: T√¨m experience section theo keyword
            sections = self.extract_sections(text)
            exp_section = sections.get('experience', '')
            
            # B∆Ø·ªöC 2: N·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c section, t√¨m theo keyword trong to√†n b·ªô text
            if not exp_section:
                exp_keywords = ['work experience', 'experience', 'kinh nghi·ªám', 'c√¥ng vi·ªác', 'employment']
                for keyword in exp_keywords:
                    if keyword.lower() in text.lower():
                        # T√¨m ƒëo·∫°n text sau keyword
                        start_idx = text.lower().find(keyword.lower())
                        if start_idx != -1:
                            # L·∫•y 800 k√Ω t·ª± sau keyword
                            exp_text = text[start_idx:start_idx + 800]
                            exp_section = exp_text
                            break
            
            # B∆Ø·ªöC 3: N·∫øu v·∫´n kh√¥ng c√≥, t√¨m pattern kinh nghi·ªám t·ª± do
            if not exp_section:
                exp_section = self._find_free_form_experience(text)
            
            # B∆Ø·ªöC 4: Parse experience t·ª´ section t√¨m ƒë∆∞·ª£c
            if exp_section:
                experience = self._parse_experience_blocks(exp_section)
            
            # B∆Ø·ªöC 5: N·∫øu v·∫´n kh√¥ng c√≥, t·∫°o experience t·ª´ projects
            if not experience:
                experience = self._create_experience_from_projects(text)
            
            return experience
            
        except Exception as e:
            logger.error(f"Error extracting experience: {e}")
            return []

    def _find_free_form_experience(self, text: str) -> str:
        """T√¨m kinh nghi·ªám trong CV c√≥ c·∫•u tr√∫c t·ª± do"""
        try:
            lines = text.split('\n')
            exp_lines = []
            in_experience_section = False
            
            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue
                
                # T√¨m b·∫Øt ƒë·∫ßu section experience
                exp_start_keywords = [
                    'work experience', 'experience', 'kinh nghi·ªám', 'c√¥ng vi·ªác',
                    'employment history', 'professional experience'
                ]
                
                if any(keyword in line.lower() for keyword in exp_start_keywords):
                    in_experience_section = True
                    continue
                
                # T√¨m k·∫øt th√∫c section (g·∫∑p section kh√°c)
                if in_experience_section:
                    section_end_keywords = [
                        'education', 'h·ªçc v·∫•n', 'skills', 'k·ªπ nƒÉng', 'projects',
                        'd·ª± √°n', 'certifications', 'ch·ª©ng ch·ªâ'
                    ]
                    
                    if any(keyword in line.lower() for keyword in section_end_keywords):
                        break
                    
                    # Th√™m d√≤ng v√†o experience
                    if len(line) > 5:  # B·ªè qua d√≤ng qu√° ng·∫Øn
                        exp_lines.append(line)
                
                # N·∫øu ch∆∞a v√†o experience section, t√¨m pattern kinh nghi·ªám
                elif not in_experience_section and i < len(lines) - 1:
                    # Pattern: Job Title - Company | Duration
                    if self._looks_like_experience_line(line, lines[i+1] if i+1 < len(lines) else ""):
                        in_experience_section = True
                        exp_lines.append(line)
                        if i+1 < len(lines):
                            exp_lines.append(lines[i+1])
            
            return '\n'.join(exp_lines)
            
        except Exception as e:
            logger.error(f"Error finding free-form experience: {e}")
            return ""

    def _looks_like_experience_line(self, line: str, next_line: str) -> bool:
        """Ki·ªÉm tra xem d√≤ng c√≥ v·∫ª l√† experience line kh√¥ng"""
        line_lower = line.lower()
        next_line_lower = next_line.lower()
        
        # Pattern 1: Job Title - Company
        if ' - ' in line or ' | ' in line:
            return True
        
        # Pattern 2: Job Title ·ªü d√≤ng 1, Company ·ªü d√≤ng 2
        job_keywords = ['developer', 'engineer', 'manager', 'specialist', 'analyst', 'designer']
        if any(keyword in line_lower for keyword in job_keywords):
            if len(line) < 50:  # Job title th∆∞·ªùng ng·∫Øn
                return True
        
        # Pattern 3: C√≥ t·ª´ kh√≥a kinh nghi·ªám
        exp_keywords = ['experience', 'kinh nghi·ªám', 'worked', 'developed', 'created']
        if any(keyword in line_lower for keyword in exp_keywords):
            return True
        
        return False

    def _parse_experience_blocks(self, exp_section: str) -> List[Dict]:
        """Parse experience blocks t·ª´ section text"""
        experience = []
        
        try:
            # T√°ch theo d·∫•u xu·ªëng d√≤ng k√©p
            exp_blocks = re.split(r'\n\s*\n', exp_section)
            
            for block in exp_blocks:
                if not block.strip():
                    continue
                    
                lines = block.split('\n')
                if len(lines) >= 2:
                    job_info = {
                        'title': lines[0].strip(),
                        'company': '',
                        'duration': '',
                        'description': '\n'.join(lines[1:]).strip()
                    }
                    
                    # T√¨m company v√† duration trong d√≤ng th·ª© 2
                    if len(lines) >= 2:
                        second_line = lines[1]
                        # Pattern: Company Name | Duration ho·∫∑c Company Name - Duration
                        company_duration = re.match(r'(.+?)\s*[|‚Äì-]\s*(.+)', second_line)
                        if company_duration:
                            job_info['company'] = company_duration.group(1).strip()
                            job_info['duration'] = company_duration.group(2).strip()
                        else:
                            job_info['company'] = second_line.strip()
                    
                    experience.append(job_info)
            
            return experience
            
        except Exception as e:
            logger.error(f"Error parsing experience blocks: {e}")
            return []

    def _create_experience_from_projects(self, text: str) -> List[Dict]:
        """T·∫°o experience t·ª´ projects n·∫øu kh√¥ng t√¨m ƒë∆∞·ª£c experience th·ª±c t·∫ø"""
        try:
            projects = self.extract_projects(text)
            experience = []
            
            if projects:
                for project in projects:
                    exp_info = {
                        'title': f"Project: {project.get('name', 'Unknown')}",
                        'company': 'Personal Project',
                        'duration': 'Current',
                        'description': project.get('description', '')
                    }
                    experience.append(exp_info)
            
            # N·∫øu kh√¥ng c√≥ projects, t·∫°o experience t·ª´ skills
            if not experience:
                skills = self.extract_skills(text)
                if skills:
                    exp_info = {
                        'title': 'Freelance Developer',
                        'company': 'Various Projects',
                        'duration': 'Current',
                        'description': f'Developed projects using: {", ".join(skills[:5])}'
                    }
                    experience.append(exp_info)
            
            return experience
            
        except Exception as e:
            logger.error(f"Error creating experience from projects: {e}")
            return []

    def extract_education(self, text: str) -> List[Dict]:
        """Tr√≠ch xu·∫•t th√¥ng tin h·ªçc v·∫•n"""
        education = []
        sections = self.extract_sections(text)
        edu_section = sections.get('education', '')
        
        if not edu_section:
            return education
        
        # T√¨m c√°c block education
        edu_blocks = re.split(r'\n\s*\n', edu_section)
        
        for block in edu_blocks:
            if not block.strip():
                continue
                
            lines = block.split('\n')
            if len(lines) >= 2:
                edu_info = {
                    'degree': lines[0].strip(),
                    'school': '',
                    'year': '',
                    'description': '\n'.join(lines[1:]).strip()
                }
                
                # T√¨m school v√† year
                if len(lines) >= 2:
                    second_line = lines[1]
                    # Pattern: School Name | Year
                    school_year = re.match(r'(.+?)\s*[|‚Äì-]\s*(.+)', second_line)
                    if school_year:
                        edu_info['school'] = school_year.group(1).strip()
                        edu_info['year'] = school_year.group(2).strip()
                    else:
                        edu_info['school'] = second_line.strip()
                
                education.append(edu_info)
        
        return education

    def extract_projects(self, text: str) -> List[Dict]:
        """Tr√≠ch xu·∫•t th√¥ng tin d·ª± √°n"""
        projects = []
        sections = self.extract_sections(text)
        proj_section = sections.get('projects', '')
        
        if not proj_section:
            return projects
        
        # T√¨m c√°c block project
        proj_blocks = re.split(r'\n\s*\n', proj_section)
        
        for block in proj_blocks:
            if not block.strip():
                continue
                
            lines = block.split('\n')
            if len(lines) >= 2:
                proj_info = {
                    'name': lines[0].strip(),
                    'description': '\n'.join(lines[1:]).strip()
                }
                projects.append(proj_info)
        
        return projects

    def parse_cv(self, file_path: str, job_category: str = None) -> Dict:
        """Parse CV v√† tr·∫£ v·ªÅ th√¥ng tin chi ti·∫øt"""
        try:
            # Tr√≠ch xu·∫•t text
            text = self.extract_text_from_file(file_path)
            if not text:
                return {"error": "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t text t·ª´ file"}
            
            # Tr√≠ch xu·∫•t c√°c th√¥ng tin
            job_title = self.extract_job_title(text)
            sections = self.extract_sections(text)
            skills = self.extract_skills(text, job_category)
            experience = self.extract_experience(text)
            education = self.extract_education(text)
            projects = self.extract_projects(text)
            summary = self.extract_summary(text)
            
            # Debug logging
            print(f"üîç CV Parser Debug:")
            print(f"   Job Title: {job_title}")
            print(f"   Summary: {summary[:100] if summary else 'None'}...")
            print(f"   Experience: {len(experience)} entries")
            print(f"   Education: {len(education)} entries")
            print(f"   Skills: {len(skills)} skills")
            print(f"   Projects: {len(projects)} projects")
            
            return {
                "raw_text": text,
                "job_title": job_title,
                "sections": sections,
                "skills": skills,
                "experience": experience,
                "education": education,
                "projects": projects,
                "summary": summary,
                "parsed_successfully": True
            }
            
        except Exception as e:
            logger.error(f"Error parsing CV: {str(e)}")
            return {
                "error": f"L·ªói khi parse CV: {str(e)}",
                "parsed_successfully": False
            }

# T·∫°o instance global
cv_parser = IntelligentCVParser()

def parse_cv_file(file_path: str, job_category: str = None) -> Dict:
    """Wrapper function ƒë·ªÉ parse CV file"""
    return cv_parser.parse_cv(file_path, job_category) 